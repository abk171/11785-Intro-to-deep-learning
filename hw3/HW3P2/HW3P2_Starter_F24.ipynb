{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Homework 3 ASR task\n",
        "This is all my code for HW3. You can find all (surviving, unfortunately wandb got full and we deleted all runs by mistake) runs in the wandb link [here](https://wandb.ai/abk171-university-of-pittsburgh/hw3p2-ablations?nw=nwuserabk171). \\\\\n",
        "My ablations were in 3 main areas:\n",
        "\n",
        "1. Embedding: \\\\\n",
        "    I tried few simple convolution networks but eventually settled on convnext (partly because I couldnt get a chance to implement it in hw2). I use a `conv1d` layer with stride 2 and kernel size 15 as this was the best context window size in HW1P2 for me.\n",
        "\n",
        "    The best embedding layer is like so:\n",
        "    \n",
        "    ```\n",
        "    self.embedding = torch.nn.Sequential(\n",
        "        nn.Conv1d(in_channels= input_size,\n",
        "                out_channels= 48,\n",
        "                kernel_size= config['kernel_size'],\n",
        "                stride= 2,\n",
        "                padding= 1),\n",
        "        ConvNeXtBlock1D(dim=48, out_dim=96),\n",
        "        ConvNeXtBlock1D(dim=96, out_dim=192),\n",
        "        ConvNeXtBlock1D(dim=192, out_dim=192),\n",
        "        ConvNeXtBlock1D(dim=192, out_dim=192),\n",
        "        ConvNeXtBlock1D(dim=192, out_dim=384)\n",
        "    )\n",
        "    ```\n",
        "    This is a very small implementation of convnext which follows the recommended 1:1:3:1 ratio and cuts the dimension sizes by half.\n",
        "\n",
        "2. PBLSTM: \\\\\n",
        "    Simple pBLSTM, only used 1 layer.\n",
        "\n",
        "3. Decoder: \\\\\n",
        "    Again, related to the best archtecture from my HW1P2.\n",
        "    However, I changed to `GELU()` activation. I experimented with `dropout` and `batchnorm` but wasn't able to see good results. I suspect because of very low learning rate.\n",
        "\n",
        "\n",
        "Further, I also implemented time and frequency masking, but hardly saw any improvement from those.\n",
        "\n",
        "I kept the beam widths as high as I could in both cases to try and get stable results.\n",
        "\n",
        "Thank you for taking the time to grade my work."
      ],
      "metadata": {
        "id": "35JdnjF45u0c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR4qfYrVoO4v"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA9qZoIDcx-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a76c93-0148-40f5-cd6c-3abbe665639f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m769.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m124.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchtext==0.14.1 torchaudio==0.13.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu117 -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONgAWhqdoYy-"
      },
      "source": [
        "\n",
        "This may take a while"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SS7a7xeEoaV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd6669c-168d-4145-a9fc-47cd7d91ad40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchsummaryX==1.3.0\n",
            "  Downloading torchsummaryX-1.3.0-py3-none-any.whl.metadata (325 bytes)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchsummaryX==1.3.0) (1.13.1+cu117)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchsummaryX==1.3.0) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torchsummaryX==1.3.0) (2.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsummaryX==1.3.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsummaryX==1.3.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsummaryX==1.3.0) (2024.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX==1.3.0) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->torchsummaryX==1.3.0) (1.16.0)\n",
            "Downloading torchsummaryX-1.3.0-py3-none-any.whl (3.6 kB)\n",
            "Installing collected packages: torchsummaryX\n",
            "Successfully installed torchsummaryX-1.3.0\n",
            "Collecting pandas==1.5.2\n",
            "  Downloading pandas-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.2) (2024.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.2) (1.26.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.2) (1.16.0)\n",
            "Downloading pandas-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.17.0 requires pandas>=1.5.3, but you have pandas 1.5.2 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 1.5.2 which is incompatible.\n",
            "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.2 which is incompatible.\n",
            "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.2 which is incompatible.\n",
            "xarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.5.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.5.2\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.5/317.5 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCloning into 'ctcdecode'...\n",
            "remote: Enumerating objects: 1102, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 1102 (delta 16), reused 32 (delta 14), pack-reused 1063 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1102/1102), 782.27 KiB | 2.58 MiB/s, done.\n",
            "Resolving deltas: 100% (529/529), done.\n",
            "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n",
            "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n",
            "Cloning into '/content/ctcdecode/third_party/ThreadPool'...\n",
            "remote: Enumerating objects: 82, done.        \n",
            "remote: Counting objects: 100% (26/26), done.        \n",
            "remote: Compressing objects: 100% (9/9), done.        \n",
            "Receiving objects: 100% (82/82), 13.34 KiB | 262.00 KiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n",
            "remote: Total 82 (delta 19), reused 17 (delta 17), pack-reused 56 (from 1)        \n",
            "Cloning into '/content/ctcdecode/third_party/kenlm'...\n",
            "remote: Enumerating objects: 14170, done.        \n",
            "remote: Counting objects: 100% (483/483), done.        \n",
            "remote: Compressing objects: 100% (337/337), done.        \n",
            "remote: Total 14170 (delta 167), reused 410 (delta 132), pack-reused 13687 (from 1)        \n",
            "Receiving objects: 100% (14170/14170), 5.91 MiB | 11.13 MiB/s, done.\n",
            "Resolving deltas: 100% (8047/8047), done.\n",
            "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n",
            "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content/ctcdecode\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ctcdecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummaryX==1.3.0\n",
        "!pip install pandas==1.5.2\n",
        "!pip install wandb --quiet\n",
        "!pip install python-Levenshtein -q\n",
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!pip install wget -q\n",
        "%cd ctcdecode\n",
        "!pip install . -q\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWVONJxCobPc"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78ZTCIXoof2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd557c7b-a238-412d-c7d3-5155a1c413a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummaryX import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import torchaudio.transforms as tat\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# imports for decoding and distance calculation\n",
        "import ctcdecode\n",
        "import Levenshtein\n",
        "from ctcdecode import CTCBeamDecoder\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg3-yJ8tok34"
      },
      "source": [
        "# Kaggle Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdUelfGhom1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b588662-e41c-46dd-d3e8-afbe80dd0c51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8 -q\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "    f.write('{\"username\":\"abhigyankishor\",\"key\":\"ce53f67a6b84738c6b11d7917e02e653\"}') # TODO: Put your kaggle username & key here\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSjBwfXeoq4B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5991263b-e0db-49b9-f6fb-99009657b8f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 11-785-hw3p2-f24.zip to /content\n",
            " 99% 3.95G/3.97G [00:26<00:00, 188MB/s]\n",
            "100% 3.97G/3.97G [00:26<00:00, 159MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c 11-785-hw3p2-f24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ruxWP60LCQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1defb36f-86ee-419b-bb83-4dd0ac9776ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11785-f24-hw3p2  11-785-hw3p2-f24.zip  ctcdecode  sample_data\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "This will take a couple minutes, but you should see at least the following:\n",
        "11-785-f24-hw3p2  ctcdecode  hw3p2asr-f24.zip  sample_data\n",
        "'''\n",
        "!unzip -q 11-785-hw3p2-f24.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9v5ewZDMpYA"
      },
      "source": [
        "# Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Cp-716IMZRd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ORNHnSFroP0"
      },
      "source": [
        "# Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0v7wHRWrqH6"
      },
      "outputs": [],
      "source": [
        "# ARPABET PHONEME MAPPING\n",
        "# DO NOT CHANGE\n",
        "\n",
        "CMUdict_ARPAbet = {\n",
        "    \"\" : \" \",\n",
        "    \"[SIL]\": \"-\", \"NG\": \"G\", \"F\" : \"f\", \"M\" : \"m\", \"AE\": \"@\",\n",
        "    \"R\"    : \"r\", \"UW\": \"u\", \"N\" : \"n\", \"IY\": \"i\", \"AW\": \"W\",\n",
        "    \"V\"    : \"v\", \"UH\": \"U\", \"OW\": \"o\", \"AA\": \"a\", \"ER\": \"R\",\n",
        "    \"HH\"   : \"h\", \"Z\" : \"z\", \"K\" : \"k\", \"CH\": \"C\", \"W\" : \"w\",\n",
        "    \"EY\"   : \"e\", \"ZH\": \"Z\", \"T\" : \"t\", \"EH\": \"E\", \"Y\" : \"y\",\n",
        "    \"AH\"   : \"A\", \"B\" : \"b\", \"P\" : \"p\", \"TH\": \"T\", \"DH\": \"D\",\n",
        "    \"AO\"   : \"c\", \"G\" : \"g\", \"L\" : \"l\", \"JH\": \"j\", \"OY\": \"O\",\n",
        "    \"SH\"   : \"S\", \"D\" : \"d\", \"AY\": \"Y\", \"S\" : \"s\", \"IH\": \"I\",\n",
        "    \"[SOS]\": \"[SOS]\", \"[EOS]\": \"[EOS]\"\n",
        "}\n",
        "\n",
        "CMUdict = list(CMUdict_ARPAbet.keys())\n",
        "ARPAbet = list(CMUdict_ARPAbet.values())\n",
        "\n",
        "\n",
        "PHONEMES = CMUdict[:-2]\n",
        "LABELS = ARPAbet[:-2]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN2kcxwXLLBb"
      },
      "outputs": [],
      "source": [
        "# You might want to play around with the mapping as a sanity check here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agmNBKf4JrLV"
      },
      "source": [
        "### Train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afd0_vlbJmr_"
      },
      "outputs": [],
      "source": [
        "class AudioDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    # For this homework, we give you full flexibility to design your data set class.\n",
        "    # Hint: The data from HW1 is very similar to this HW\n",
        "\n",
        "    #TODO\n",
        "    def __init__(self,\n",
        "                 PHONEMES,\n",
        "                 mfcc_dir,\n",
        "                 transcript_dir,\n",
        "                 freq_mask_param,\n",
        "                 time_mask_param,\n",
        "                 fraction= 1,):\n",
        "        '''\n",
        "        Initializes the dataset.\n",
        "\n",
        "        INPUTS: What inputs do you need here?\n",
        "        '''\n",
        "\n",
        "        # Load the directory and all files in them\n",
        "        self.time_mask = tat.TimeMasking(time_mask_param= time_mask_param, iid_masks=True)\n",
        "        self.freq_mask = tat.FrequencyMasking(freq_mask_param= freq_mask_param, iid_masks=True)\n",
        "\n",
        "        self.mfcc_dir = mfcc_dir\n",
        "        self.transcript_dir = transcript_dir\n",
        "\n",
        "        self.mfcc_files = sorted(os.listdir(self.mfcc_dir))\n",
        "        self.transcript_files = sorted(os.listdir(self.transcript_dir))\n",
        "\n",
        "        self.phonemes = PHONEMES\n",
        "        self.fraction = fraction\n",
        "\n",
        "        #TODO\n",
        "        # WHAT SHOULD THE LENGTH OF THE DATASET BE?\n",
        "        self.length = len(self.mfcc_files)\n",
        "\n",
        "        #TODO\n",
        "        # HOW CAN WE REPRESENT PHONEMES? CAN WE CREATE A MAPPING FOR THEM?\n",
        "        # HINT: TENSORS CANNOT STORE NON-NUMERICAL VALUES OR STRINGS\n",
        "        self.phoneme_map = {p: i for i, p in enumerate(self.phonemes)}\n",
        "\n",
        "        #TODO\n",
        "        # CREATE AN ARRAY OF ALL FEATUERS AND LABELS\n",
        "        # WHAT NORMALIZATION TECHNIQUE DID YOU USE IN HW1? CAN WE USE IT HERE?\n",
        "        self.mfccs, self.transcripts = [], []\n",
        "\n",
        "        for i, (mfcc_file, transcript_file) in enumerate(zip(self.mfcc_files, self.transcript_files)):\n",
        "            if i == int(self.length * fraction):\n",
        "                break\n",
        "            mfcc = np.load(os.path.join(self.mfcc_dir, mfcc_file))\n",
        "            transcript = np.load(os.path.join(self.transcript_dir, transcript_file))[1:-1]\n",
        "\n",
        "            mean_mfcc   = np.mean(mfcc, axis = 0)\n",
        "            std_mfcc = np.std(mfcc, axis = 0) + 1e-8\n",
        "            mfcc  = (mfcc - mean_mfcc) / std_mfcc\n",
        "\n",
        "            self.mfccs.append(mfcc)\n",
        "            self.transcripts.append(transcript)\n",
        "        '''\n",
        "        You may decide to do this in __getitem__ if you wish.\n",
        "        However, doing this here will make the __init__ function take the load of\n",
        "        loading the data, and shift it away from training.\n",
        "        '''\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        '''\n",
        "        TODO: What do we return here?\n",
        "        '''\n",
        "        return int(self.length * self.fraction)\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        '''\n",
        "        TODO: RETURN THE MFCC COEFFICIENTS AND ITS CORRESPONDING LABELS\n",
        "\n",
        "        If you didn't do the loading and processing of the data in __init__,\n",
        "        do that here.\n",
        "\n",
        "        Once done, return a tuple of features and labels.\n",
        "        '''\n",
        "\n",
        "        # raise NotImplemented\n",
        "\n",
        "        mfcc =  self.mfccs[ind]# TODO\n",
        "        transcript = self.transcripts[ind]# TODO\n",
        "        mapped_transcript = np.vectorize(lambda x: self.phoneme_map[x])(transcript)\n",
        "        return torch.FloatTensor(mfcc), torch.tensor(mapped_transcript)\n",
        "\n",
        "\n",
        "    def collate_fn(self,batch):\n",
        "        '''\n",
        "        TODO:\n",
        "        1.  Extract the features and labels from 'batch'\n",
        "        2.  We will additionally need to pad both features and labels,\n",
        "            look at pytorch's docs for pad_sequence\n",
        "        3.  This is a good place to perform transforms, if you so wish.\n",
        "            Performing them on batches will speed the process up a bit.\n",
        "        4.  Return batch of features, labels, lenghts of features,\n",
        "            and lengths of labels.\n",
        "        '''\n",
        "        batch_mfcc, batch_transcript = zip(*batch)\n",
        "\n",
        "        # HINT: CHECK OUT -> pad_sequence (imported above)\n",
        "        # Also be sure to check the input format (batch_first)\n",
        "        batch_mfcc_pad = pad_sequence(batch_mfcc, batch_first=True) # TODO\n",
        "        lengths_mfcc = torch.tensor([mfcc.shape[0] for mfcc in batch_mfcc]) # TODO\n",
        "\n",
        "        batch_transcript_pad = pad_sequence(batch_transcript, batch_first=True) # TODO\n",
        "        lengths_transcript = torch.tensor([transcript.shape[0] for transcript in batch_transcript]) # TODO\n",
        "\n",
        "        # You may apply some transformation, Time and Frequency masking, here in the collate function;\n",
        "        # Food for thought -> Why are we applying the transformation here and not in the __getitem__?\n",
        "        #                  -> Would we apply transformation on the validation set as well?\n",
        "        #                  -> Is the order of axes / dimensions as expected for the transform functions?\n",
        "        # batch_mfcc_pad.transpose(1, 2)\n",
        "        # batch_mfcc_pad = self.time_mask(batch_mfcc_pad)\n",
        "        # batch_mfcc_pad = self.freq_mask(batch_mfcc_pad)\n",
        "        # batch_mfcc_pad.transpose(1, 2)\n",
        "\n",
        "        # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
        "        return batch_mfcc_pad, batch_transcript_pad, torch.tensor(lengths_mfcc), torch.tensor(lengths_transcript)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqDrxeHfJw4g"
      },
      "source": [
        "### Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrLS1wfVJppA"
      },
      "outputs": [],
      "source": [
        "class AudioDatasetTest(torch.utils.data.Dataset):\n",
        "\n",
        "    # For this homework, we give you full flexibility to design your data set class.\n",
        "    # Hint: The data from HW1 is very similar to this HW\n",
        "\n",
        "    #TODO\n",
        "    def __init__(self,\n",
        "                 PHONEMES,\n",
        "                 mfcc_dir,\n",
        "                 fraction= 1):\n",
        "        '''\n",
        "        Initializes the dataset.\n",
        "\n",
        "        INPUTS: What inputs do you need here?\n",
        "        '''\n",
        "\n",
        "        # Load the directory and all files in them\n",
        "\n",
        "        self.mfcc_dir = mfcc_dir\n",
        "\n",
        "        self.mfcc_files = sorted(os.listdir(self.mfcc_dir))\n",
        "\n",
        "        self.phonemes = PHONEMES\n",
        "\n",
        "        #TODO\n",
        "        # WHAT SHOULD THE LENGTH OF THE DATASET BE?\n",
        "        self.length = len(self.mfcc_files)\n",
        "        self.fraction = fraction\n",
        "\n",
        "        #TODO\n",
        "        # HOW CAN WE REPRESENT PHONEMES? CAN WE CREATE A MAPPING FOR THEM?\n",
        "        # HINT: TENSORS CANNOT STORE NON-NUMERICAL VALUES OR STRINGS\n",
        "        self.phoneme_map = {p: i for i, p in enumerate(self.phonemes)}\n",
        "\n",
        "        #TODO\n",
        "        # CREATE AN ARRAY OF ALL FEATUERS AND LABELS\n",
        "        # WHAT NORMALIZATION TECHNIQUE DID YOU USE IN HW1? CAN WE USE IT HERE?\n",
        "        self.mfccs = []\n",
        "\n",
        "        for i, mfcc_file in enumerate(self.mfcc_files):\n",
        "            if i == int(self.length * fraction):\n",
        "                break\n",
        "            mfcc = np.load(os.path.join(self.mfcc_dir, mfcc_file))\n",
        "\n",
        "            mean_mfcc   = np.mean(mfcc, axis = 0)\n",
        "            std_mfcc = np.std(mfcc, axis = 0) + 1e-8\n",
        "            mfcc  = (mfcc - mean_mfcc) / std_mfcc\n",
        "\n",
        "            self.mfccs.append(mfcc)\n",
        "        '''\n",
        "        You may decide to do this in __getitem__ if you wish.\n",
        "        However, doing this here will make the __init__ function take the load of\n",
        "        loading the data, and shift it away from training.\n",
        "        '''\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        '''\n",
        "        TODO: What do we return here?\n",
        "        '''\n",
        "        return int(self.length * self.fraction)\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        '''\n",
        "        TODO: RETURN THE MFCC COEFFICIENTS AND ITS CORRESPONDING LABELS\n",
        "\n",
        "        If you didn't do the loading and processing of the data in __init__,\n",
        "        do that here.\n",
        "\n",
        "        Once done, return a tuple of features and labels.\n",
        "        '''\n",
        "\n",
        "        # raise NotImplemented\n",
        "\n",
        "        mfcc =  self.mfccs[ind]# TODO\n",
        "        return torch.FloatTensor(mfcc)\n",
        "\n",
        "\n",
        "\n",
        "    def collate_fn(self,batch):\n",
        "        '''\n",
        "        TODO:\n",
        "        1.  Extract the features and labels from 'batch'\n",
        "        2.  We will additionally need to pad both features and labels,\n",
        "            look at pytorch's docs for pad_sequence\n",
        "        3.  This is a good place to perform transforms, if you so wish.\n",
        "            Performing them on batches will speed the process up a bit.\n",
        "        4.  Return batch of features, labels, lenghts of features,\n",
        "            and lengths of labels.\n",
        "        '''\n",
        "        batch_mfcc= [mfcc for mfcc in batch]\n",
        "\n",
        "        # HINT: CHECK OUT -> pad_sequence (imported above)\n",
        "        # Also be sure to check the input format (batch_first)\n",
        "        batch_mfcc_pad = pad_sequence(batch_mfcc, batch_first=True) # TODO\n",
        "        lengths_mfcc = torch.tensor([mfcc.shape[0] for mfcc in batch_mfcc]) # TODO\n",
        "\n",
        "        # You may apply some transformation, Time and Frequency masking, here in the collate function;\n",
        "        # Food for thought -> Why are we applying the transformation here and not in the __getitem__?\n",
        "        #                  -> Would we apply transformation on the validation set as well?\n",
        "        #                  -> Is the order of axes / dimensions as expected for the transform functions?\n",
        "\n",
        "\n",
        "        # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
        "        return batch_mfcc_pad, torch.tensor(lengths_mfcc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt-veYcdL6Fe"
      },
      "source": [
        "### Config - Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN82c3KpLup8"
      },
      "outputs": [],
      "source": [
        "root = '/content/11-785-f24-hw3p2/'\n",
        "\n",
        "config = {\n",
        "    ## data directories\n",
        "    'mfcc_train_dir'         : '/content/11785-f24-hw3p2/train-clean-100/mfcc',\n",
        "    'mfcc_val_dir'           : '/content/11785-f24-hw3p2/dev-clean/mfcc',\n",
        "    'mfcc_test_dir'          : '/content/11785-f24-hw3p2/test-clean/mfcc',\n",
        "\n",
        "    'transcript_train_dir'   : '/content/11785-f24-hw3p2/train-clean-100/transcript',\n",
        "    'transcript_val_dir'     : '/content/11785-f24-hw3p2/dev-clean/transcript',\n",
        "\n",
        "    'time_mask_param'        : 0,\n",
        "    'freq_mask_param'        : 0,\n",
        "\n",
        "    'fraction'               : 1,\n",
        "\n",
        "\n",
        "\n",
        "    # general\n",
        "    \"beam_width\" : 4,\n",
        "    \"lr\"         : 2e-3,\n",
        "    \"epochs\"     : 50,\n",
        "    \"batch_size\" : 64,  # Increase if your device can handle it\n",
        "\n",
        "    # basic network\n",
        "    \"embedding_size\" : 64,\n",
        "    \"hidden_size\"    : 256,\n",
        "    \"kernel_size\"    : 15,\n",
        "    \"dropout\"        : 0.2,\n",
        "    \"bidirectional\"  : True,\n",
        "\n",
        "    #optimizer\n",
        "    'weight_decay'   : 1e-4,\n",
        "\n",
        "    #scheduler\n",
        "    'factor'         : 0.8,\n",
        "    'patience'       : 2,\n",
        "    'threshold'      : 1e-1,\n",
        "    'min_lr'         : 1e-5\n",
        "}\n",
        "\n",
        "# Feel free to add more items here\n",
        "\n",
        "# You may pass this as a parameter to the dataset class above\n",
        "# This will help modularize your implementation\n",
        "transforms = [] # set of tranformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmuPk9J6L8dz"
      },
      "source": [
        "### Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_kG0gU2x4hH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46133d6d-9b15-4404-b985-594f4105f258"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# get me RAMMM!!!!\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mzoYfTKu14s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d50e70-6953-4b88-e888-79cab5feb6e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size:  64\n",
            "Train dataset samples = 28539, batches = 446\n",
            "Val dataset samples = 2703, batches = 43\n",
            "Test dataset samples = 2620, batches = 41\n"
          ]
        }
      ],
      "source": [
        "# Create objects for the dataset class\n",
        "train_data = AudioDataset(PHONEMES, config['mfcc_train_dir'], config['transcript_train_dir'], config['freq_mask_param'], config['time_mask_param'], config['fraction']) #TODO\n",
        "val_data = AudioDataset(PHONEMES, config['mfcc_val_dir'], config['transcript_val_dir'], 0, 0, config['fraction']) # TODO : You can either use the same class with some modifications or make a new one :)\n",
        "test_data = AudioDatasetTest(PHONEMES, config['mfcc_test_dir'], config['fraction']) #TODO\n",
        "\n",
        "# Do NOT forget to pass in the collate function as parameter while creating the dataloader\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = train_data,\n",
        "    num_workers = 4,\n",
        "    batch_size  = config['batch_size'],\n",
        "    pin_memory  = True,\n",
        "    shuffle     = True,\n",
        "    collate_fn  = train_data.collate_fn\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = val_data,\n",
        "    num_workers = 1,\n",
        "    batch_size  = config['batch_size'],\n",
        "    pin_memory  = True,\n",
        "    shuffle     = False,\n",
        "    collate_fn  = val_data.collate_fn\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = test_data,\n",
        "    num_workers = 1,\n",
        "    batch_size  = config['batch_size'],\n",
        "    pin_memory  = True,\n",
        "    shuffle     = False,\n",
        "    collate_fn  = test_data.collate_fn\n",
        ")\n",
        "\n",
        "print(\"Batch size: \", config['batch_size'])\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXMtwyviKaxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc1952f-4e00-4e8c-f625-11a7901db01e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1696, 28]) torch.Size([64, 199]) torch.Size([64]) torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "# sanity check\n",
        "for data in train_loader:\n",
        "    x, y, lx, ly = data\n",
        "    print(x.shape, y.shape, lx.shape, ly.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSexxhdfMUzx"
      },
      "source": [
        "# NETWORK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLad4pChcuvX"
      },
      "source": [
        "## Basic\n",
        "\n",
        "This is a basic block for understanding, you can skip this and move to pBLSTM one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQhvHr71GJfq"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "class Network(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        # Adding some sort of embedding layer or feature extractor might help performance.\n",
        "        self.embedding = nn.Conv1d(in_channels= 28,\n",
        "                                         out_channels= config['embedding_size'],\n",
        "                                         kernel_size= config['kernel_size'],\n",
        "                                         stride= 2,\n",
        "                                         padding= 1)\n",
        "\n",
        "\n",
        "        # TODO : look up the documentation. You might need to pass some additional parameters.\n",
        "        self.lstm = nn.LSTM(input_size = config['embedding_size'],\n",
        "                            hidden_size = config['hidden_size'],\n",
        "                            num_layers = 3,\n",
        "                            batch_first= True,\n",
        "                            dropout= config['dropout'],\n",
        "                            bidirectional= config['bidirectional'])\n",
        "\n",
        "        recv_size = 2* config['batch_size'] if config['bidirectional'] else config['batch_size']\n",
        "        self.classification = torch.nn.Sequential( #maybe change the hidden size to be normal 256,512...\n",
        "            # PermuteBlock(),\n",
        "            # torch.nn.BatchNorm1d(2 * config['hidden_size'] if config['bidirectional'] else config['hidden_size']),\n",
        "            # PermuteBlock(),\n",
        "            torch.nn.Linear(in_features=recv_size,out_features=len(PHONEMES)),\n",
        "            # torch.nn.GELU(),\n",
        "            # torch.nn.Linear(in_features=128, out_features=64),\n",
        "            # torch.nn.GELU(),\n",
        "            # torch.nn.Linear(in_features=64, out_features=len(PHONEMES))\n",
        "        )\n",
        "\n",
        "\n",
        "        self.logSoftmax = nn.LogSoftmax(dim=-1)#TODO: Apply a log softmax here. Which dimension would apply it on ?\n",
        "\n",
        "    def forward(self, x, lx):\n",
        "        #TODO\n",
        "        # The forward function takes 2 parameter inputs here. Why?\n",
        "        # Refer to the handout for hints\n",
        "\n",
        "        x = x.transpose(1, 2).contiguous()\n",
        "        x = self.embedding(x)\n",
        "        x = x.transpose(1, 2).contiguous()\n",
        "\n",
        "        lx = (lx + 2 - config['kernel_size']) // 2  + 1\n",
        "\n",
        "        x = pack_padded_sequence(x, lx, batch_first= True, enforce_sorted= False)\n",
        "        x = self.lstm(x)[0]\n",
        "        x, lx = pad_packed_sequence(x, batch_first= True)\n",
        "\n",
        "        x = self.classification(x)\n",
        "        x = self.logSoftmax(x)\n",
        "\n",
        "        return x, lx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUThsowyQdN7"
      },
      "source": [
        "## Initialize Basic Network\n",
        "(If trying out the basic Network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGoiXd70tb5z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "outputId": "82741cf0-0f49-4f79-f925-6d76d55f5e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============================================================================================\n",
            "                                         Kernel Shape      Output Shape  \\\n",
            "Layer                                                                     \n",
            "0_embedding.0.Linear_residual_connection     [28, 64]   [256, 2936, 64]   \n",
            "1_embedding.0.Conv1d_dwconv               [1, 28, 15]   [256, 28, 2936]   \n",
            "2_embedding.0.LayerNorm_norm                     [28]   [256, 2936, 28]   \n",
            "3_embedding.0.Linear_pwconv1                [28, 112]  [256, 2936, 112]   \n",
            "4_embedding.0.GELU_act                              -  [256, 2936, 112]   \n",
            "5_embedding.0.Linear_pwconv2                [112, 64]   [256, 2936, 64]   \n",
            "6_lstm                                              -      [89014, 512]   \n",
            "7_classification.Linear_0                   [512, 41]   [256, 1462, 41]   \n",
            "8_logSoftmax                                        -   [256, 1462, 41]   \n",
            "\n",
            "                                             Params  Mult-Adds  \n",
            "Layer                                                           \n",
            "0_embedding.0.Linear_residual_connection     1.856k     1.792k  \n",
            "1_embedding.0.Conv1d_dwconv                   448.0   1.23312M  \n",
            "2_embedding.0.LayerNorm_norm                   56.0       28.0  \n",
            "3_embedding.0.Linear_pwconv1                 3.248k     3.136k  \n",
            "4_embedding.0.GELU_act                            -          -  \n",
            "5_embedding.0.Linear_pwconv2                 7.232k     7.168k  \n",
            "6_lstm                                    3.813376M  3.801088M  \n",
            "7_classification.Linear_0                   21.033k    20.992k  \n",
            "8_logSoftmax                                      -          -  \n",
            "---------------------------------------------------------------------------------------------\n",
            "                         Totals\n",
            "Total params          3.847249M\n",
            "Trainable params      3.847249M\n",
            "Non-trainable params        0.0\n",
            "Mult-Adds             5.067324M\n",
            "=============================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         Kernel Shape      Output Shape  \\\n",
              "Layer                                                                     \n",
              "0_embedding.0.Linear_residual_connection     [28, 64]   [256, 2936, 64]   \n",
              "1_embedding.0.Conv1d_dwconv               [1, 28, 15]   [256, 28, 2936]   \n",
              "2_embedding.0.LayerNorm_norm                     [28]   [256, 2936, 28]   \n",
              "3_embedding.0.Linear_pwconv1                [28, 112]  [256, 2936, 112]   \n",
              "4_embedding.0.GELU_act                              -  [256, 2936, 112]   \n",
              "5_embedding.0.Linear_pwconv2                [112, 64]   [256, 2936, 64]   \n",
              "6_lstm                                              -      [89014, 512]   \n",
              "7_classification.Linear_0                   [512, 41]   [256, 1462, 41]   \n",
              "8_logSoftmax                                        -   [256, 1462, 41]   \n",
              "\n",
              "                                             Params  Mult-Adds  \n",
              "Layer                                                           \n",
              "0_embedding.0.Linear_residual_connection     1856.0     1792.0  \n",
              "1_embedding.0.Conv1d_dwconv                   448.0  1233120.0  \n",
              "2_embedding.0.LayerNorm_norm                   56.0       28.0  \n",
              "3_embedding.0.Linear_pwconv1                 3248.0     3136.0  \n",
              "4_embedding.0.GELU_act                          NaN        NaN  \n",
              "5_embedding.0.Linear_pwconv2                 7232.0     7168.0  \n",
              "6_lstm                                    3813376.0  3801088.0  \n",
              "7_classification.Linear_0                   21033.0    20992.0  \n",
              "8_logSoftmax                                    NaN        NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d604e99a-085b-4c6f-9c68-702847a8ed41\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_embedding.0.Linear_residual_connection</th>\n",
              "      <td>[28, 64]</td>\n",
              "      <td>[256, 2936, 64]</td>\n",
              "      <td>1856.0</td>\n",
              "      <td>1792.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_embedding.0.Conv1d_dwconv</th>\n",
              "      <td>[1, 28, 15]</td>\n",
              "      <td>[256, 28, 2936]</td>\n",
              "      <td>448.0</td>\n",
              "      <td>1233120.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_embedding.0.LayerNorm_norm</th>\n",
              "      <td>[28]</td>\n",
              "      <td>[256, 2936, 28]</td>\n",
              "      <td>56.0</td>\n",
              "      <td>28.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_embedding.0.Linear_pwconv1</th>\n",
              "      <td>[28, 112]</td>\n",
              "      <td>[256, 2936, 112]</td>\n",
              "      <td>3248.0</td>\n",
              "      <td>3136.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_embedding.0.GELU_act</th>\n",
              "      <td>-</td>\n",
              "      <td>[256, 2936, 112]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_embedding.0.Linear_pwconv2</th>\n",
              "      <td>[112, 64]</td>\n",
              "      <td>[256, 2936, 64]</td>\n",
              "      <td>7232.0</td>\n",
              "      <td>7168.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_lstm</th>\n",
              "      <td>-</td>\n",
              "      <td>[89014, 512]</td>\n",
              "      <td>3813376.0</td>\n",
              "      <td>3801088.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_classification.Linear_0</th>\n",
              "      <td>[512, 41]</td>\n",
              "      <td>[256, 1462, 41]</td>\n",
              "      <td>21033.0</td>\n",
              "      <td>20992.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8_logSoftmax</th>\n",
              "      <td>-</td>\n",
              "      <td>[256, 1462, 41]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d604e99a-085b-4c6f-9c68-702847a8ed41')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d604e99a-085b-4c6f-9c68-702847a8ed41 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d604e99a-085b-4c6f-9c68-702847a8ed41');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-36f5dcf9-e6a5-4cba-93fa-eeb1c57d67ca\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36f5dcf9-e6a5-4cba-93fa-eeb1c57d67ca')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-36f5dcf9-e6a5-4cba-93fa-eeb1c57d67ca button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"summary(model, x\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"Layer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"7_classification.Linear_0\",\n          \"1_embedding.0.Conv1d_dwconv\",\n          \"5_embedding.0.Linear_pwconv2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kernel Shape\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Output Shape\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Params\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1439205.2449891688,\n        \"min\": 56.0,\n        \"max\": 3813376.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1856.0,\n          448.0,\n          3813376.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mult-Adds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1431846.5229493997,\n        \"min\": 28.0,\n        \"max\": 3801088.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1792.0,\n          1233120.0,\n          3801088.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "model = Network().to(device)\n",
        "summary(model, x.to(device), lx) # x and lx come from the sanity check above :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-qb7wnAzCZl"
      },
      "source": [
        "## ASR Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB6eh3gnMUzy"
      },
      "source": [
        "### Pyramid Bi-LSTM (pBLSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd4BEX_yMUzz"
      },
      "outputs": [],
      "source": [
        "# Utils for network\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "class PermuteBlock(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.transpose(1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class LockedDropout(nn.Module):\n",
        "    def __init__(self, p = 0.25):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not self.training or not self.p:\n",
        "            return x\n",
        "        x = x.clone()\n",
        "        mask = x.new_empty(1, x.size(1), x.size(2), requires_grad=False).bernoulli_(1 - self.p)\n",
        "        mask = mask.div_(1 - self.p)\n",
        "        mask = mask.expand_as(x)\n",
        "        return x * mask\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(' \\\n",
        "            + 'p=' + str(self.p) + ')'"
      ],
      "metadata": {
        "id": "f3Evmhqf7yKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmdyXI6KMUzz"
      },
      "outputs": [],
      "source": [
        "class pBLSTM(torch.nn.Module):\n",
        "\n",
        "    '''\n",
        "    Pyramidal BiLSTM\n",
        "    Read the write up/paper and understand the concepts and then write your implementation here.\n",
        "\n",
        "    At each step,\n",
        "    1. Pad your input if it is packed (Unpack it)\n",
        "    2. Reduce the input length dimension by concatenating feature dimension\n",
        "        (Tip: Write down the shapes and understand)\n",
        "        (i) How should  you deal with odd/even length input?\n",
        "        (ii) How should you deal with input length array (x_lens) after truncating the input?\n",
        "    3. Pack your input\n",
        "    4. Pass it into LSTM layer\n",
        "\n",
        "    To make our implementation modular, we pass 1 layer at a time.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(pBLSTM, self).__init__()\n",
        "\n",
        "        self.blstm = torch.nn.LSTM(input_size=2*input_size, hidden_size=hidden_size, num_layers=3, bidirectional=True, dropout = 0.3)# TODO: Initialize a single layer bidirectional LSTM with the given input_size and hidden_size\n",
        "\n",
        "    def forward(self, x_packed): # x_packed is a PackedSequence\n",
        "\n",
        "        # TODO: Pad Packed Sequence\n",
        "        seq_unpacked, lens_unpacked = pad_packed_sequence(x_packed, batch_first=True)\n",
        "        # Call self.trunc_reshape() which downsamples the time steps of x and increases the feature dimensions as mentioned above\n",
        "        x, x_lens = self.trunc_reshape(x=seq_unpacked, x_lens=lens_unpacked)\n",
        "        # self.trunc_reshape will return 2 outputs. What are they? Think about what quantites are changing.\n",
        "        # TODO: Pack Padded Sequence. What output(s) would you get?\n",
        "        PackedSequence = pack_padded_sequence(input=x,lengths=x_lens,batch_first=True,enforce_sorted=False)\n",
        "        # TODO: Pass the sequence through bLSTM\n",
        "        packed_output, (_, _) = self.blstm(PackedSequence)\n",
        "        # What do you return?\n",
        "\n",
        "        return packed_output\n",
        "\n",
        "    def trunc_reshape(self, x, x_lens):\n",
        "        b, t, c = x.shape\n",
        "        # TODO: If you have odd number of timesteps, how can you handle it? (Hint: You can exclude them)\n",
        "        if t % 2 == 1:\n",
        "            x = x[:, :-1, :]\n",
        "        # TODO: Reshape x. When reshaping x, you have to reduce number of timesteps by a downsampling factor while increasing number of features by the same factor\n",
        "        x = x.reshape(b, x.shape[1] // 2, c * 2)\n",
        "        # TODO: Reduce lengths by the same downsampling factor\n",
        "        return x, x_lens / 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3ZQ75OcMUz0"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConvNeXtBlock1D(nn.Module):\n",
        "    def __init__(self, dim, out_dim, layer_scale_init_value=1e-6, drop_path=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dwconv = nn.Conv1d(dim, dim, kernel_size=7, padding=3, groups=dim)  # depthwise conv\n",
        "\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "\n",
        "        self.pwconv1 = nn.Linear(dim, 4 * dim)\n",
        "        self.act = nn.GELU()\n",
        "        self.pwconv2 = nn.Linear(4 * dim, out_dim)\n",
        "\n",
        "        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((out_dim,)), requires_grad=True) if layer_scale_init_value > 0 else None\n",
        "\n",
        "        self.residual_connection = nn.Linear(dim,out_dim) if dim != out_dim else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        residual = residual.transpose(1, 2)\n",
        "        residual = self.norm(residual)\n",
        "        residual = self.residual_connection(residual)\n",
        "\n",
        "        x = self.dwconv(x)\n",
        "\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.norm(x)\n",
        "        x = self.pwconv1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.pwconv2(x)\n",
        "\n",
        "        if self.gamma is not None:\n",
        "          x = self.gamma * x\n",
        "\n",
        "        x = x.transpose(1, 2)\n",
        "        residual = residual.transpose(1,2)\n",
        "\n",
        "        return residual + x"
      ],
      "metadata": {
        "id": "wahfkepYJnlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEzw5_xmMUz0"
      },
      "outputs": [],
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    '''\n",
        "    The Encoder takes utterances as inputs and returns latent feature representations\n",
        "    '''\n",
        "    def __init__(self, input_size, encoder_hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "\n",
        "       #TODO: You can use CNNs as Embedding layer to extract features. Keep in mind the Input dimensions and expected dimension of Pytorch CNN.\n",
        "        self.embedding = torch.nn.Sequential(\n",
        "            nn.Conv1d(in_channels= input_size,\n",
        "                    out_channels= 64,\n",
        "                    kernel_size= config['kernel_size'],\n",
        "                    stride= 2,\n",
        "                    padding= 1),\n",
        "            # ConvNeXtBlock1D(dim=input_size, out_dim=64),\n",
        "            ConvNeXtBlock1D(dim=64, out_dim=128),\n",
        "            ConvNeXtBlock1D(dim=128, out_dim=256),\n",
        "            ConvNeXtBlock1D(dim=256, out_dim=256),\n",
        "            ConvNeXtBlock1D(dim=256, out_dim=256),\n",
        "            # ConvNeXtBlock1D(dim=256, out_dim=384)\n",
        "        )\n",
        "\n",
        "        # self.pBLSTMs = torch.nn.Sequential( # How many pBLSTMs are required?\n",
        "            # TODO: Fill this up with pBLSTMs - What should the input_size be?\n",
        "            # Hint: You are downsampling timesteps by a factor of 2, upsampling features by a factor of 2 and the LSTM is bidirectional)\n",
        "            # Optional: Dropout/Locked Dropout after each pBLSTM (Not needed for early submission)\n",
        "            # https://github.com/salesforce/awd-lstm-lm/blob/dfd3cb0235d2caf2847a4d53e1cbd495b781b5d2/locked_dropout.py#L5\n",
        "            # ...\n",
        "            # ...\n",
        "\n",
        "        # )\n",
        "        self.lstm_layers = torch.nn.ModuleList()\n",
        "        for i in range(1):\n",
        "            input_size_pblstm = 256 if i == 0 else encoder_hidden_size * 2\n",
        "            self.lstm_layers.append(pBLSTM(input_size=input_size_pblstm, hidden_size=encoder_hidden_size))\n",
        "            self.lstm_layers.append(LockedDropout())\n",
        "\n",
        "    def forward(self, x, x_lens):\n",
        "        # Where are x and x_lens coming from? The dataloader\n",
        "        #TODO: Call the embedding layer\n",
        "        # TODO: Pack Padded Sequence\n",
        "        # TODO: Pass Sequence through the pyramidal Bi-LSTM layer\n",
        "        # TODO: Pad Packed Sequence\n",
        "\n",
        "        x = x.transpose(1, 2).contiguous()\n",
        "        x = self.embedding(x)\n",
        "        x = x.transpose(1, 2).contiguous()\n",
        "\n",
        "        x_lens = (x_lens + 2 - config['kernel_size']) // 2  + 1\n",
        "\n",
        "        for layer in self.lstm_layers:\n",
        "            if isinstance(layer, pBLSTM):\n",
        "                x_packed = pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
        "                x_packed = layer(x_packed)\n",
        "                x, x_lens = pad_packed_sequence(x_packed, batch_first=True)\n",
        "            else:\n",
        "                x = torch.permute(x, (1, 0, 2))\n",
        "                x = layer(x)\n",
        "                x = torch.permute(x,(1,0,2))\n",
        "\n",
        "        # Remember the number of output(s) each function returns\n",
        "\n",
        "        return x, x_lens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg82HXa3MUz1"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQIRxdNTMUz1"
      },
      "outputs": [],
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, embed_size, output_size= 41):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            PermuteBlock(), torch.nn.BatchNorm1d(embed_size), PermuteBlock(),\n",
        "            #TODO define your MLP arch. Refer HW1P2\n",
        "            #Use Permute Block before and after BatchNorm1d() to match the size\n",
        "             torch.nn.Linear(in_features=embed_size,out_features=128),\n",
        "            torch.nn.GELU(),\n",
        "            # torch.nn.Dropout(p=0.2),\n",
        "            torch.nn.Linear(in_features=128, out_features=64),\n",
        "            torch.nn.GELU(),\n",
        "            # torch.nn.Dropout(p=0.2),\n",
        "            torch.nn.Linear(in_features=64, out_features=output_size)\n",
        "        )\n",
        "\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=2)\n",
        "\n",
        "    def forward(self, encoder_out):\n",
        "        #TODO call your MLP\n",
        "        #TODO Think what should be the final output of the decoder for the classification\n",
        "        out = self.mlp(encoder_out)\n",
        "        out = self.softmax(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV7DMPDoMUz2"
      },
      "source": [
        "## Initialize ASR Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmHf6pFiMUz1"
      },
      "outputs": [],
      "source": [
        "class ASRModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, embed_size= 192, output_size= len(PHONEMES)):\n",
        "        super().__init__()\n",
        "        self.time_mask = tat.TimeMasking(time_mask_param= config['time_mask_param'], iid_masks=True)\n",
        "        self.freq_mask = tat.FrequencyMasking(freq_mask_param= config['freq_mask_param'], iid_masks=True)\n",
        "        self.augmentations  = torch.nn.Sequential(\n",
        "            #TODO Add Time Masking/ Frequency Masking\n",
        "            #Hint: See how to use PermuteBlock() function defined above\n",
        "            PermuteBlock(),\n",
        "            self.time_mask,\n",
        "            self.freq_mask,\n",
        "            PermuteBlock()\n",
        "        )\n",
        "        self.encoder        = Encoder(\n",
        "            input_size          = input_size,\n",
        "            encoder_hidden_size = embed_size * 2\n",
        "        )# TODO: Initialize Encoder\n",
        "        self.decoder        = Decoder(\n",
        "            embed_size          = 4 * embed_size,\n",
        "            output_size         = output_size\n",
        "        )# TODO: Initialize Decoder\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, lengths_x):\n",
        "\n",
        "        if self.training:\n",
        "            x = self.augmentations(x)\n",
        "\n",
        "        encoder_out, encoder_lens   = self.encoder(x, lengths_x)\n",
        "        decoder_out                 = self.decoder(encoder_out)\n",
        "\n",
        "        return decoder_out, encoder_lens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "3sLnyC2eoBcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaaDsnnLMUz2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "587b417e-7e1e-43be-f812-4a8823210cc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ASRModel(\n",
            "  (time_mask): TimeMasking()\n",
            "  (freq_mask): FrequencyMasking()\n",
            "  (augmentations): Sequential(\n",
            "    (0): PermuteBlock()\n",
            "    (1): TimeMasking()\n",
            "    (2): FrequencyMasking()\n",
            "    (3): PermuteBlock()\n",
            "  )\n",
            "  (encoder): Encoder(\n",
            "    (embedding): Sequential(\n",
            "      (0): Conv1d(28, 64, kernel_size=(15,), stride=(2,), padding=(1,))\n",
            "      (1): ConvNeXtBlock1D(\n",
            "        (dwconv): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), groups=64)\n",
            "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (pwconv1): Linear(in_features=64, out_features=256, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (pwconv2): Linear(in_features=256, out_features=128, bias=True)\n",
            "        (residual_connection): Linear(in_features=64, out_features=128, bias=True)\n",
            "      )\n",
            "      (2): ConvNeXtBlock1D(\n",
            "        (dwconv): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128)\n",
            "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "        (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (pwconv2): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (residual_connection): Linear(in_features=128, out_features=256, bias=True)\n",
            "      )\n",
            "      (3): ConvNeXtBlock1D(\n",
            "        (dwconv): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), groups=256)\n",
            "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (residual_connection): Identity()\n",
            "      )\n",
            "      (4): ConvNeXtBlock1D(\n",
            "        (dwconv): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), groups=256)\n",
            "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        (residual_connection): Identity()\n",
            "      )\n",
            "    )\n",
            "    (lstm_layers): ModuleList(\n",
            "      (0): pBLSTM(\n",
            "        (blstm): LSTM(512, 384, num_layers=3, dropout=0.3, bidirectional=True)\n",
            "      )\n",
            "      (1): LockedDropout(p=0.25)\n",
            "    )\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (mlp): Sequential(\n",
            "      (0): PermuteBlock()\n",
            "      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PermuteBlock()\n",
            "      (3): Linear(in_features=768, out_features=128, bias=True)\n",
            "      (4): GELU(approximate='none')\n",
            "      (5): Linear(in_features=128, out_features=64, bias=True)\n",
            "      (6): GELU(approximate='none')\n",
            "      (7): Linear(in_features=64, out_features=41, bias=True)\n",
            "    )\n",
            "    (softmax): LogSoftmax(dim=2)\n",
            "  )\n",
            ")\n",
            "==========================================================================================================\n",
            "                                                    Kernel Shape  \\\n",
            "Layer                                                              \n",
            "0_augmentations.PermuteBlock_0                                 -   \n",
            "1_augmentations.TimeMasking_1                                  -   \n",
            "2_augmentations.TimeMasking_1                                  -   \n",
            "3_augmentations.FrequencyMasking_2                             -   \n",
            "4_augmentations.FrequencyMasking_2                             -   \n",
            "5_augmentations.PermuteBlock_3                                 -   \n",
            "6_encoder.embedding.Conv1d_0                        [28, 64, 15]   \n",
            "7_encoder.embedding.1.LayerNorm_norm                        [64]   \n",
            "8_encoder.embedding.1.Linear_residual_connection       [64, 128]   \n",
            "9_encoder.embedding.1.Conv1d_dwconv                   [1, 64, 7]   \n",
            "10_encoder.embedding.1.LayerNorm_norm                       [64]   \n",
            "11_encoder.embedding.1.Linear_pwconv1                  [64, 256]   \n",
            "12_encoder.embedding.1.GELU_act                                -   \n",
            "13_encoder.embedding.1.Linear_pwconv2                 [256, 128]   \n",
            "14_encoder.embedding.2.LayerNorm_norm                      [128]   \n",
            "15_encoder.embedding.2.Linear_residual_connection     [128, 256]   \n",
            "16_encoder.embedding.2.Conv1d_dwconv                 [1, 128, 7]   \n",
            "17_encoder.embedding.2.LayerNorm_norm                      [128]   \n",
            "18_encoder.embedding.2.Linear_pwconv1                 [128, 512]   \n",
            "19_encoder.embedding.2.GELU_act                                -   \n",
            "20_encoder.embedding.2.Linear_pwconv2                 [512, 256]   \n",
            "21_encoder.embedding.3.LayerNorm_norm                      [256]   \n",
            "22_encoder.embedding.3.Identity_residual_connec...             -   \n",
            "23_encoder.embedding.3.Conv1d_dwconv                 [1, 256, 7]   \n",
            "24_encoder.embedding.3.LayerNorm_norm                      [256]   \n",
            "25_encoder.embedding.3.Linear_pwconv1                [256, 1024]   \n",
            "26_encoder.embedding.3.GELU_act                                -   \n",
            "27_encoder.embedding.3.Linear_pwconv2                [1024, 256]   \n",
            "28_encoder.embedding.4.LayerNorm_norm                      [256]   \n",
            "29_encoder.embedding.4.Identity_residual_connec...             -   \n",
            "30_encoder.embedding.4.Conv1d_dwconv                 [1, 256, 7]   \n",
            "31_encoder.embedding.4.LayerNorm_norm                      [256]   \n",
            "32_encoder.embedding.4.Linear_pwconv1                [256, 1024]   \n",
            "33_encoder.embedding.4.GELU_act                                -   \n",
            "34_encoder.embedding.4.Linear_pwconv2                [1024, 256]   \n",
            "35_encoder.lstm_layers.0.LSTM_blstm                            -   \n",
            "36_encoder.lstm_layers.LockedDropout_1                         -   \n",
            "37_decoder.mlp.PermuteBlock_0                                  -   \n",
            "38_decoder.mlp.BatchNorm1d_1                               [768]   \n",
            "39_decoder.mlp.PermuteBlock_2                                  -   \n",
            "40_decoder.mlp.Linear_3                               [768, 128]   \n",
            "41_decoder.mlp.GELU_4                                          -   \n",
            "42_decoder.mlp.Linear_5                                [128, 64]   \n",
            "43_decoder.mlp.GELU_6                                          -   \n",
            "44_decoder.mlp.Linear_7                                 [64, 41]   \n",
            "45_decoder.LogSoftmax_softmax                                  -   \n",
            "\n",
            "                                                        Output Shape  \\\n",
            "Layer                                                                  \n",
            "0_augmentations.PermuteBlock_0                        [64, 28, 2936]   \n",
            "1_augmentations.TimeMasking_1                         [64, 28, 2936]   \n",
            "2_augmentations.TimeMasking_1                         [64, 28, 2936]   \n",
            "3_augmentations.FrequencyMasking_2                    [64, 28, 2936]   \n",
            "4_augmentations.FrequencyMasking_2                    [64, 28, 2936]   \n",
            "5_augmentations.PermuteBlock_3                        [64, 2936, 28]   \n",
            "6_encoder.embedding.Conv1d_0                          [64, 64, 1462]   \n",
            "7_encoder.embedding.1.LayerNorm_norm                  [64, 1462, 64]   \n",
            "8_encoder.embedding.1.Linear_residual_connection     [64, 1462, 128]   \n",
            "9_encoder.embedding.1.Conv1d_dwconv                   [64, 64, 1462]   \n",
            "10_encoder.embedding.1.LayerNorm_norm                 [64, 1462, 64]   \n",
            "11_encoder.embedding.1.Linear_pwconv1                [64, 1462, 256]   \n",
            "12_encoder.embedding.1.GELU_act                      [64, 1462, 256]   \n",
            "13_encoder.embedding.1.Linear_pwconv2                [64, 1462, 128]   \n",
            "14_encoder.embedding.2.LayerNorm_norm                [64, 1462, 128]   \n",
            "15_encoder.embedding.2.Linear_residual_connection    [64, 1462, 256]   \n",
            "16_encoder.embedding.2.Conv1d_dwconv                 [64, 128, 1462]   \n",
            "17_encoder.embedding.2.LayerNorm_norm                [64, 1462, 128]   \n",
            "18_encoder.embedding.2.Linear_pwconv1                [64, 1462, 512]   \n",
            "19_encoder.embedding.2.GELU_act                      [64, 1462, 512]   \n",
            "20_encoder.embedding.2.Linear_pwconv2                [64, 1462, 256]   \n",
            "21_encoder.embedding.3.LayerNorm_norm                [64, 1462, 256]   \n",
            "22_encoder.embedding.3.Identity_residual_connec...   [64, 1462, 256]   \n",
            "23_encoder.embedding.3.Conv1d_dwconv                 [64, 256, 1462]   \n",
            "24_encoder.embedding.3.LayerNorm_norm                [64, 1462, 256]   \n",
            "25_encoder.embedding.3.Linear_pwconv1               [64, 1462, 1024]   \n",
            "26_encoder.embedding.3.GELU_act                     [64, 1462, 1024]   \n",
            "27_encoder.embedding.3.Linear_pwconv2                [64, 1462, 256]   \n",
            "28_encoder.embedding.4.LayerNorm_norm                [64, 1462, 256]   \n",
            "29_encoder.embedding.4.Identity_residual_connec...   [64, 1462, 256]   \n",
            "30_encoder.embedding.4.Conv1d_dwconv                 [64, 256, 1462]   \n",
            "31_encoder.embedding.4.LayerNorm_norm                [64, 1462, 256]   \n",
            "32_encoder.embedding.4.Linear_pwconv1               [64, 1462, 1024]   \n",
            "33_encoder.embedding.4.GELU_act                     [64, 1462, 1024]   \n",
            "34_encoder.embedding.4.Linear_pwconv2                [64, 1462, 256]   \n",
            "35_encoder.lstm_layers.0.LSTM_blstm                     [10336, 768]   \n",
            "36_encoder.lstm_layers.LockedDropout_1                [731, 64, 768]   \n",
            "37_decoder.mlp.PermuteBlock_0                         [64, 768, 731]   \n",
            "38_decoder.mlp.BatchNorm1d_1                          [64, 768, 731]   \n",
            "39_decoder.mlp.PermuteBlock_2                         [64, 731, 768]   \n",
            "40_decoder.mlp.Linear_3                               [64, 731, 128]   \n",
            "41_decoder.mlp.GELU_4                                 [64, 731, 128]   \n",
            "42_decoder.mlp.Linear_5                                [64, 731, 64]   \n",
            "43_decoder.mlp.GELU_6                                  [64, 731, 64]   \n",
            "44_decoder.mlp.Linear_7                                [64, 731, 41]   \n",
            "45_decoder.LogSoftmax_softmax                          [64, 731, 41]   \n",
            "\n",
            "                                                       Params  Mult-Adds  \n",
            "Layer                                                                     \n",
            "0_augmentations.PermuteBlock_0                              -          -  \n",
            "1_augmentations.TimeMasking_1                               -          -  \n",
            "2_augmentations.TimeMasking_1                               -          -  \n",
            "3_augmentations.FrequencyMasking_2                          -          -  \n",
            "4_augmentations.FrequencyMasking_2                          -          -  \n",
            "5_augmentations.PermuteBlock_3                              -          -  \n",
            "6_encoder.embedding.Conv1d_0                          26.944k  39.29856M  \n",
            "7_encoder.embedding.1.LayerNorm_norm                    128.0       64.0  \n",
            "8_encoder.embedding.1.Linear_residual_connection        8.32k     8.192k  \n",
            "9_encoder.embedding.1.Conv1d_dwconv                     512.0   654.976k  \n",
            "10_encoder.embedding.1.LayerNorm_norm                       -       64.0  \n",
            "11_encoder.embedding.1.Linear_pwconv1                  16.64k    16.384k  \n",
            "12_encoder.embedding.1.GELU_act                             -          -  \n",
            "13_encoder.embedding.1.Linear_pwconv2                 32.896k    32.768k  \n",
            "14_encoder.embedding.2.LayerNorm_norm                   256.0      128.0  \n",
            "15_encoder.embedding.2.Linear_residual_connection     33.024k    32.768k  \n",
            "16_encoder.embedding.2.Conv1d_dwconv                   1.024k  1.309952M  \n",
            "17_encoder.embedding.2.LayerNorm_norm                       -      128.0  \n",
            "18_encoder.embedding.2.Linear_pwconv1                 66.048k    65.536k  \n",
            "19_encoder.embedding.2.GELU_act                             -          -  \n",
            "20_encoder.embedding.2.Linear_pwconv2                131.328k   131.072k  \n",
            "21_encoder.embedding.3.LayerNorm_norm                   512.0      256.0  \n",
            "22_encoder.embedding.3.Identity_residual_connec...          -          -  \n",
            "23_encoder.embedding.3.Conv1d_dwconv                   2.048k  2.619904M  \n",
            "24_encoder.embedding.3.LayerNorm_norm                       -      256.0  \n",
            "25_encoder.embedding.3.Linear_pwconv1                263.168k   262.144k  \n",
            "26_encoder.embedding.3.GELU_act                             -          -  \n",
            "27_encoder.embedding.3.Linear_pwconv2                  262.4k   262.144k  \n",
            "28_encoder.embedding.4.LayerNorm_norm                   512.0      256.0  \n",
            "29_encoder.embedding.4.Identity_residual_connec...          -          -  \n",
            "30_encoder.embedding.4.Conv1d_dwconv                   2.048k  2.619904M  \n",
            "31_encoder.embedding.4.LayerNorm_norm                       -      256.0  \n",
            "32_encoder.embedding.4.Linear_pwconv1                263.168k   262.144k  \n",
            "33_encoder.embedding.4.GELU_act                             -          -  \n",
            "34_encoder.embedding.4.Linear_pwconv2                  262.4k   262.144k  \n",
            "35_encoder.lstm_layers.0.LSTM_blstm                 9.848832M    9.8304M  \n",
            "36_encoder.lstm_layers.LockedDropout_1                      -          -  \n",
            "37_decoder.mlp.PermuteBlock_0                               -          -  \n",
            "38_decoder.mlp.BatchNorm1d_1                           1.536k      768.0  \n",
            "39_decoder.mlp.PermuteBlock_2                               -          -  \n",
            "40_decoder.mlp.Linear_3                               98.432k    98.304k  \n",
            "41_decoder.mlp.GELU_4                                       -          -  \n",
            "42_decoder.mlp.Linear_5                                8.256k     8.192k  \n",
            "43_decoder.mlp.GELU_6                                       -          -  \n",
            "44_decoder.mlp.Linear_7                                2.665k     2.624k  \n",
            "45_decoder.LogSoftmax_softmax                               -          -  \n",
            "----------------------------------------------------------------------------------------------------------\n",
            "                          Totals\n",
            "Total params          11.333097M\n",
            "Trainable params      11.333097M\n",
            "Non-trainable params         0.0\n",
            "Mult-Adds             57.780288M\n",
            "==========================================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    Kernel Shape  \\\n",
              "Layer                                                              \n",
              "0_augmentations.PermuteBlock_0                                 -   \n",
              "1_augmentations.TimeMasking_1                                  -   \n",
              "2_augmentations.TimeMasking_1                                  -   \n",
              "3_augmentations.FrequencyMasking_2                             -   \n",
              "4_augmentations.FrequencyMasking_2                             -   \n",
              "5_augmentations.PermuteBlock_3                                 -   \n",
              "6_encoder.embedding.Conv1d_0                        [28, 64, 15]   \n",
              "7_encoder.embedding.1.LayerNorm_norm                        [64]   \n",
              "8_encoder.embedding.1.Linear_residual_connection       [64, 128]   \n",
              "9_encoder.embedding.1.Conv1d_dwconv                   [1, 64, 7]   \n",
              "10_encoder.embedding.1.LayerNorm_norm                       [64]   \n",
              "11_encoder.embedding.1.Linear_pwconv1                  [64, 256]   \n",
              "12_encoder.embedding.1.GELU_act                                -   \n",
              "13_encoder.embedding.1.Linear_pwconv2                 [256, 128]   \n",
              "14_encoder.embedding.2.LayerNorm_norm                      [128]   \n",
              "15_encoder.embedding.2.Linear_residual_connection     [128, 256]   \n",
              "16_encoder.embedding.2.Conv1d_dwconv                 [1, 128, 7]   \n",
              "17_encoder.embedding.2.LayerNorm_norm                      [128]   \n",
              "18_encoder.embedding.2.Linear_pwconv1                 [128, 512]   \n",
              "19_encoder.embedding.2.GELU_act                                -   \n",
              "20_encoder.embedding.2.Linear_pwconv2                 [512, 256]   \n",
              "21_encoder.embedding.3.LayerNorm_norm                      [256]   \n",
              "22_encoder.embedding.3.Identity_residual_connec...             -   \n",
              "23_encoder.embedding.3.Conv1d_dwconv                 [1, 256, 7]   \n",
              "24_encoder.embedding.3.LayerNorm_norm                      [256]   \n",
              "25_encoder.embedding.3.Linear_pwconv1                [256, 1024]   \n",
              "26_encoder.embedding.3.GELU_act                                -   \n",
              "27_encoder.embedding.3.Linear_pwconv2                [1024, 256]   \n",
              "28_encoder.embedding.4.LayerNorm_norm                      [256]   \n",
              "29_encoder.embedding.4.Identity_residual_connec...             -   \n",
              "30_encoder.embedding.4.Conv1d_dwconv                 [1, 256, 7]   \n",
              "31_encoder.embedding.4.LayerNorm_norm                      [256]   \n",
              "32_encoder.embedding.4.Linear_pwconv1                [256, 1024]   \n",
              "33_encoder.embedding.4.GELU_act                                -   \n",
              "34_encoder.embedding.4.Linear_pwconv2                [1024, 256]   \n",
              "35_encoder.lstm_layers.0.LSTM_blstm                            -   \n",
              "36_encoder.lstm_layers.LockedDropout_1                         -   \n",
              "37_decoder.mlp.PermuteBlock_0                                  -   \n",
              "38_decoder.mlp.BatchNorm1d_1                               [768]   \n",
              "39_decoder.mlp.PermuteBlock_2                                  -   \n",
              "40_decoder.mlp.Linear_3                               [768, 128]   \n",
              "41_decoder.mlp.GELU_4                                          -   \n",
              "42_decoder.mlp.Linear_5                                [128, 64]   \n",
              "43_decoder.mlp.GELU_6                                          -   \n",
              "44_decoder.mlp.Linear_7                                 [64, 41]   \n",
              "45_decoder.LogSoftmax_softmax                                  -   \n",
              "\n",
              "                                                        Output Shape  \\\n",
              "Layer                                                                  \n",
              "0_augmentations.PermuteBlock_0                        [64, 28, 2936]   \n",
              "1_augmentations.TimeMasking_1                         [64, 28, 2936]   \n",
              "2_augmentations.TimeMasking_1                         [64, 28, 2936]   \n",
              "3_augmentations.FrequencyMasking_2                    [64, 28, 2936]   \n",
              "4_augmentations.FrequencyMasking_2                    [64, 28, 2936]   \n",
              "5_augmentations.PermuteBlock_3                        [64, 2936, 28]   \n",
              "6_encoder.embedding.Conv1d_0                          [64, 64, 1462]   \n",
              "7_encoder.embedding.1.LayerNorm_norm                  [64, 1462, 64]   \n",
              "8_encoder.embedding.1.Linear_residual_connection     [64, 1462, 128]   \n",
              "9_encoder.embedding.1.Conv1d_dwconv                   [64, 64, 1462]   \n",
              "10_encoder.embedding.1.LayerNorm_norm                 [64, 1462, 64]   \n",
              "11_encoder.embedding.1.Linear_pwconv1                [64, 1462, 256]   \n",
              "12_encoder.embedding.1.GELU_act                      [64, 1462, 256]   \n",
              "13_encoder.embedding.1.Linear_pwconv2                [64, 1462, 128]   \n",
              "14_encoder.embedding.2.LayerNorm_norm                [64, 1462, 128]   \n",
              "15_encoder.embedding.2.Linear_residual_connection    [64, 1462, 256]   \n",
              "16_encoder.embedding.2.Conv1d_dwconv                 [64, 128, 1462]   \n",
              "17_encoder.embedding.2.LayerNorm_norm                [64, 1462, 128]   \n",
              "18_encoder.embedding.2.Linear_pwconv1                [64, 1462, 512]   \n",
              "19_encoder.embedding.2.GELU_act                      [64, 1462, 512]   \n",
              "20_encoder.embedding.2.Linear_pwconv2                [64, 1462, 256]   \n",
              "21_encoder.embedding.3.LayerNorm_norm                [64, 1462, 256]   \n",
              "22_encoder.embedding.3.Identity_residual_connec...   [64, 1462, 256]   \n",
              "23_encoder.embedding.3.Conv1d_dwconv                 [64, 256, 1462]   \n",
              "24_encoder.embedding.3.LayerNorm_norm                [64, 1462, 256]   \n",
              "25_encoder.embedding.3.Linear_pwconv1               [64, 1462, 1024]   \n",
              "26_encoder.embedding.3.GELU_act                     [64, 1462, 1024]   \n",
              "27_encoder.embedding.3.Linear_pwconv2                [64, 1462, 256]   \n",
              "28_encoder.embedding.4.LayerNorm_norm                [64, 1462, 256]   \n",
              "29_encoder.embedding.4.Identity_residual_connec...   [64, 1462, 256]   \n",
              "30_encoder.embedding.4.Conv1d_dwconv                 [64, 256, 1462]   \n",
              "31_encoder.embedding.4.LayerNorm_norm                [64, 1462, 256]   \n",
              "32_encoder.embedding.4.Linear_pwconv1               [64, 1462, 1024]   \n",
              "33_encoder.embedding.4.GELU_act                     [64, 1462, 1024]   \n",
              "34_encoder.embedding.4.Linear_pwconv2                [64, 1462, 256]   \n",
              "35_encoder.lstm_layers.0.LSTM_blstm                     [10336, 768]   \n",
              "36_encoder.lstm_layers.LockedDropout_1                [731, 64, 768]   \n",
              "37_decoder.mlp.PermuteBlock_0                         [64, 768, 731]   \n",
              "38_decoder.mlp.BatchNorm1d_1                          [64, 768, 731]   \n",
              "39_decoder.mlp.PermuteBlock_2                         [64, 731, 768]   \n",
              "40_decoder.mlp.Linear_3                               [64, 731, 128]   \n",
              "41_decoder.mlp.GELU_4                                 [64, 731, 128]   \n",
              "42_decoder.mlp.Linear_5                                [64, 731, 64]   \n",
              "43_decoder.mlp.GELU_6                                  [64, 731, 64]   \n",
              "44_decoder.mlp.Linear_7                                [64, 731, 41]   \n",
              "45_decoder.LogSoftmax_softmax                          [64, 731, 41]   \n",
              "\n",
              "                                                       Params   Mult-Adds  \n",
              "Layer                                                                      \n",
              "0_augmentations.PermuteBlock_0                            NaN         NaN  \n",
              "1_augmentations.TimeMasking_1                             NaN         NaN  \n",
              "2_augmentations.TimeMasking_1                             NaN         NaN  \n",
              "3_augmentations.FrequencyMasking_2                        NaN         NaN  \n",
              "4_augmentations.FrequencyMasking_2                        NaN         NaN  \n",
              "5_augmentations.PermuteBlock_3                            NaN         NaN  \n",
              "6_encoder.embedding.Conv1d_0                          26944.0  39298560.0  \n",
              "7_encoder.embedding.1.LayerNorm_norm                    128.0        64.0  \n",
              "8_encoder.embedding.1.Linear_residual_connection       8320.0      8192.0  \n",
              "9_encoder.embedding.1.Conv1d_dwconv                     512.0    654976.0  \n",
              "10_encoder.embedding.1.LayerNorm_norm                     NaN        64.0  \n",
              "11_encoder.embedding.1.Linear_pwconv1                 16640.0     16384.0  \n",
              "12_encoder.embedding.1.GELU_act                           NaN         NaN  \n",
              "13_encoder.embedding.1.Linear_pwconv2                 32896.0     32768.0  \n",
              "14_encoder.embedding.2.LayerNorm_norm                   256.0       128.0  \n",
              "15_encoder.embedding.2.Linear_residual_connection     33024.0     32768.0  \n",
              "16_encoder.embedding.2.Conv1d_dwconv                   1024.0   1309952.0  \n",
              "17_encoder.embedding.2.LayerNorm_norm                     NaN       128.0  \n",
              "18_encoder.embedding.2.Linear_pwconv1                 66048.0     65536.0  \n",
              "19_encoder.embedding.2.GELU_act                           NaN         NaN  \n",
              "20_encoder.embedding.2.Linear_pwconv2                131328.0    131072.0  \n",
              "21_encoder.embedding.3.LayerNorm_norm                   512.0       256.0  \n",
              "22_encoder.embedding.3.Identity_residual_connec...        NaN         NaN  \n",
              "23_encoder.embedding.3.Conv1d_dwconv                   2048.0   2619904.0  \n",
              "24_encoder.embedding.3.LayerNorm_norm                     NaN       256.0  \n",
              "25_encoder.embedding.3.Linear_pwconv1                263168.0    262144.0  \n",
              "26_encoder.embedding.3.GELU_act                           NaN         NaN  \n",
              "27_encoder.embedding.3.Linear_pwconv2                262400.0    262144.0  \n",
              "28_encoder.embedding.4.LayerNorm_norm                   512.0       256.0  \n",
              "29_encoder.embedding.4.Identity_residual_connec...        NaN         NaN  \n",
              "30_encoder.embedding.4.Conv1d_dwconv                   2048.0   2619904.0  \n",
              "31_encoder.embedding.4.LayerNorm_norm                     NaN       256.0  \n",
              "32_encoder.embedding.4.Linear_pwconv1                263168.0    262144.0  \n",
              "33_encoder.embedding.4.GELU_act                           NaN         NaN  \n",
              "34_encoder.embedding.4.Linear_pwconv2                262400.0    262144.0  \n",
              "35_encoder.lstm_layers.0.LSTM_blstm                 9848832.0   9830400.0  \n",
              "36_encoder.lstm_layers.LockedDropout_1                    NaN         NaN  \n",
              "37_decoder.mlp.PermuteBlock_0                             NaN         NaN  \n",
              "38_decoder.mlp.BatchNorm1d_1                           1536.0       768.0  \n",
              "39_decoder.mlp.PermuteBlock_2                             NaN         NaN  \n",
              "40_decoder.mlp.Linear_3                               98432.0     98304.0  \n",
              "41_decoder.mlp.GELU_4                                     NaN         NaN  \n",
              "42_decoder.mlp.Linear_5                                8256.0      8192.0  \n",
              "43_decoder.mlp.GELU_6                                     NaN         NaN  \n",
              "44_decoder.mlp.Linear_7                                2665.0      2624.0  \n",
              "45_decoder.LogSoftmax_softmax                             NaN         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bdc37aab-9fcf-4ca4-b1d7-53177a2689f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_augmentations.PermuteBlock_0</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 28, 2936]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_augmentations.TimeMasking_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 28, 2936]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_augmentations.TimeMasking_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 28, 2936]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_augmentations.FrequencyMasking_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 28, 2936]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_augmentations.FrequencyMasking_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 28, 2936]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_augmentations.PermuteBlock_3</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 2936, 28]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_encoder.embedding.Conv1d_0</th>\n",
              "      <td>[28, 64, 15]</td>\n",
              "      <td>[64, 64, 1462]</td>\n",
              "      <td>26944.0</td>\n",
              "      <td>39298560.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_encoder.embedding.1.LayerNorm_norm</th>\n",
              "      <td>[64]</td>\n",
              "      <td>[64, 1462, 64]</td>\n",
              "      <td>128.0</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8_encoder.embedding.1.Linear_residual_connection</th>\n",
              "      <td>[64, 128]</td>\n",
              "      <td>[64, 1462, 128]</td>\n",
              "      <td>8320.0</td>\n",
              "      <td>8192.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9_encoder.embedding.1.Conv1d_dwconv</th>\n",
              "      <td>[1, 64, 7]</td>\n",
              "      <td>[64, 64, 1462]</td>\n",
              "      <td>512.0</td>\n",
              "      <td>654976.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10_encoder.embedding.1.LayerNorm_norm</th>\n",
              "      <td>[64]</td>\n",
              "      <td>[64, 1462, 64]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11_encoder.embedding.1.Linear_pwconv1</th>\n",
              "      <td>[64, 256]</td>\n",
              "      <td>[64, 1462, 256]</td>\n",
              "      <td>16640.0</td>\n",
              "      <td>16384.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12_encoder.embedding.1.GELU_act</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 1462, 256]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13_encoder.embedding.1.Linear_pwconv2</th>\n",
              "      <td>[256, 128]</td>\n",
              "      <td>[64, 1462, 128]</td>\n",
              "      <td>32896.0</td>\n",
              "      <td>32768.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14_encoder.embedding.2.LayerNorm_norm</th>\n",
              "      <td>[128]</td>\n",
              "      <td>[64, 1462, 128]</td>\n",
              "      <td>256.0</td>\n",
              "      <td>128.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15_encoder.embedding.2.Linear_residual_connection</th>\n",
              "      <td>[128, 256]</td>\n",
              "      <td>[64, 1462, 256]</td>\n",
              "      <td>33024.0</td>\n",
              "      <td>32768.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16_encoder.embedding.2.Conv1d_dwconv</th>\n",
              "      <td>[1, 128, 7]</td>\n",
              "      <td>[64, 128, 1462]</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>1309952.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17_encoder.embedding.2.LayerNorm_norm</th>\n",
              "      <td>[128]</td>\n",
              "      <td>[64, 1462, 128]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>128.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18_encoder.embedding.2.Linear_pwconv1</th>\n",
              "      <td>[128, 512]</td>\n",
              "      <td>[64, 1462, 512]</td>\n",
              "      <td>66048.0</td>\n",
              "      <td>65536.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19_encoder.embedding.2.GELU_act</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 1462, 512]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20_encoder.embedding.2.Linear_pwconv2</th>\n",
              "      <td>[512, 256]</td>\n",
              "      <td>[64, 1462, 256]</td>\n",
              "      <td>131328.0</td>\n",
              "      <td>131072.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21_encoder.embedding.3.LayerNorm_norm</th>\n",
              "      <td>[256]</td>\n",
              "      <td>[64, 1462, 256]</td>\n",
              "      <td>512.0</td>\n",
              "      <td>256.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22_encoder.embedding.3.Identity_residual_connection</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 1462, 256]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23_encoder.embedding.3.Conv1d_dwconv</th>\n",
              "      <td>[1, 256, 7]</td>\n",
              "      <td>[64, 256, 1462]</td>\n",
              "      <td>2048.0</td>\n",
              "      <td>2619904.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24_encoder.embedding.3.LayerNorm_norm</th>\n",
              "      <td>[256]</td>\n",
              "      <td>[64, 1462, 256]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>256.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25_encoder.embedding.3.Linear_pwconv1</th>\n",
              "      <td>[256, 1024]</td>\n",
              "      <td>[64, 1462, 1024]</td>\n",
              "      <td>263168.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26_encoder.embedding.3.GELU_act</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 1462, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27_encoder.embedding.3.Linear_pwconv2</th>\n",
              "      <td>[1024, 256]</td>\n",
              "      <td>[64, 1462, 256]</td>\n",
              "      <td>262400.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28_encoder.embedding.4.LayerNorm_norm</th>\n",
              "      <td>[256]</td>\n",
              "      <td>[64, 1462, 256]</td>\n",
              "      <td>512.0</td>\n",
              "      <td>256.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29_encoder.embedding.4.Identity_residual_connection</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 1462, 256]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30_encoder.embedding.4.Conv1d_dwconv</th>\n",
              "      <td>[1, 256, 7]</td>\n",
              "      <td>[64, 256, 1462]</td>\n",
              "      <td>2048.0</td>\n",
              "      <td>2619904.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31_encoder.embedding.4.LayerNorm_norm</th>\n",
              "      <td>[256]</td>\n",
              "      <td>[64, 1462, 256]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>256.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32_encoder.embedding.4.Linear_pwconv1</th>\n",
              "      <td>[256, 1024]</td>\n",
              "      <td>[64, 1462, 1024]</td>\n",
              "      <td>263168.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33_encoder.embedding.4.GELU_act</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 1462, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34_encoder.embedding.4.Linear_pwconv2</th>\n",
              "      <td>[1024, 256]</td>\n",
              "      <td>[64, 1462, 256]</td>\n",
              "      <td>262400.0</td>\n",
              "      <td>262144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35_encoder.lstm_layers.0.LSTM_blstm</th>\n",
              "      <td>-</td>\n",
              "      <td>[10336, 768]</td>\n",
              "      <td>9848832.0</td>\n",
              "      <td>9830400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36_encoder.lstm_layers.LockedDropout_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[731, 64, 768]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37_decoder.mlp.PermuteBlock_0</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 768, 731]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38_decoder.mlp.BatchNorm1d_1</th>\n",
              "      <td>[768]</td>\n",
              "      <td>[64, 768, 731]</td>\n",
              "      <td>1536.0</td>\n",
              "      <td>768.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39_decoder.mlp.PermuteBlock_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 731, 768]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40_decoder.mlp.Linear_3</th>\n",
              "      <td>[768, 128]</td>\n",
              "      <td>[64, 731, 128]</td>\n",
              "      <td>98432.0</td>\n",
              "      <td>98304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41_decoder.mlp.GELU_4</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 731, 128]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42_decoder.mlp.Linear_5</th>\n",
              "      <td>[128, 64]</td>\n",
              "      <td>[64, 731, 64]</td>\n",
              "      <td>8256.0</td>\n",
              "      <td>8192.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43_decoder.mlp.GELU_6</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 731, 64]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44_decoder.mlp.Linear_7</th>\n",
              "      <td>[64, 41]</td>\n",
              "      <td>[64, 731, 41]</td>\n",
              "      <td>2665.0</td>\n",
              "      <td>2624.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45_decoder.LogSoftmax_softmax</th>\n",
              "      <td>-</td>\n",
              "      <td>[64, 731, 41]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdc37aab-9fcf-4ca4-b1d7-53177a2689f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bdc37aab-9fcf-4ca4-b1d7-53177a2689f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bdc37aab-9fcf-4ca4-b1d7-53177a2689f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7a753713-b83b-48cc-b9b7-6c1ee5d46b26\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a753713-b83b-48cc-b9b7-6c1ee5d46b26')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7a753713-b83b-48cc-b9b7-6c1ee5d46b26 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"summary(model, x\",\n  \"rows\": 46,\n  \"fields\": [\n    {\n      \"column\": \"Layer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 46,\n        \"samples\": [\n          \"39_decoder.mlp.PermuteBlock_2\",\n          \"25_encoder.embedding.3.Linear_pwconv1\",\n          \"26_encoder.embedding.3.GELU_act\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kernel Shape\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Output Shape\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Params\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1999551.2150592108,\n        \"min\": 128.0,\n        \"max\": 9848832.0,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          26944.0,\n          32896.0,\n          2048.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mult-Adds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7547284.457798259,\n        \"min\": 64.0,\n        \"max\": 39298560.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          39298560.0,\n          64.0,\n          32768.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "model = ASRModel(\n",
        "    input_size  = 28,#TODO,\n",
        "    embed_size  = 192,#TODO\n",
        "    output_size = len(PHONEMES)\n",
        ").to(device)\n",
        "print(model)\n",
        "summary(model, x.to(device),lx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBwunYpyugFg"
      },
      "source": [
        "# Training Config\n",
        "Initialize Loss Criterion, Optimizer, CTC Beam Decoder, Scheduler, Scaler (Mixed-Precision), etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGoozH2nd6KB"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "\n",
        "\n",
        "criterion = torch.nn.CTCLoss()# Define CTC loss as the criterion. How would the losses be reduced?\n",
        "# CTC Loss: https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html\n",
        "# Refer to the handout for hints\n",
        "\n",
        "optimizer =  torch.optim.AdamW(\n",
        "    params= model.parameters(),\n",
        "    lr= config['lr'],\n",
        "    weight_decay= config['weight_decay']\n",
        ") # What goes in here?\n",
        "\n",
        "# optimizer = torch.optim.AdamW([\n",
        "#     {'params': model.encoder.embedding.parameters(), 'lr': 3e-3},\n",
        "#     {'params': model.encoder.lstm_layers.parameters(), 'lr': config['lr']},\n",
        "#     {'params': model.decoder.parameters(), 'lr':3e-3}\n",
        "# ], weight_decay= config['weight_decay'])\n",
        "\n",
        "# Declare the decoder. Use the CTC Beam Decoder to decode phonemes\n",
        "# CTC Beam Decoder Doc: https://github.com/parlance/ctcdecode\n",
        "decoder = CTCBeamDecoder(\n",
        "    labels= LABELS,\n",
        "    cutoff_top_n= 40,\n",
        "    beam_width= config['beam_width'],\n",
        "    log_probs_input= True,\n",
        "    num_processes= 2,\n",
        ")\n",
        "\n",
        "#TODO\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer= optimizer,\n",
        "                                                       patience=config['patience'],\n",
        "                                                       threshold=config['threshold'],\n",
        "                                                       factor=config['factor'], min_lr=config['min_lr'])#TODO\n",
        "\n",
        "# Mixed Precision, if you need it\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmc6_4eWL2Xp"
      },
      "source": [
        "# Decode Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHjnCDddL36E"
      },
      "outputs": [],
      "source": [
        "def decode_prediction(output, output_lens, decoder, PHONEME_MAP= LABELS):\n",
        "\n",
        "    # TODO: look at docs for CTC.decoder and find out what is returned here. Check the shape of output and expected shape in decode.\n",
        "\n",
        "    beam_results, beam_scores, timesteps, out_lens = decoder.decode(output, seq_lens= output_lens) #lengths - list of lengths\n",
        "\n",
        "    pred_strings                    = []\n",
        "\n",
        "    for i in range(output_lens.shape[0]):\n",
        "        #TODO: Create the prediction from the output of decoder.decode. Don't forget to map it using PHONEMES_MAP.\n",
        "        pred = beam_results[i][0][:out_lens[i][0]]\n",
        "        best_string = ''.join([PHONEME_MAP[x] for x in pred])\n",
        "        pred_strings.append(best_string)\n",
        "    return pred_strings\n",
        "\n",
        "def calculate_levenshtein(output, label, output_lens, label_lens, decoder, PHONEME_MAP= LABELS): # y - sequence of integers\n",
        "\n",
        "    dist            = 0\n",
        "    batch_size      = label.shape[0]\n",
        "\n",
        "    pred_strings    = decode_prediction(output, output_lens, decoder, PHONEME_MAP)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        # TODO: Get predicted string and label string for each element in the batch\n",
        "        pred_string = pred_strings[i]#TODO\n",
        "        label_index = label[i, :label_lens[i]].tolist()\n",
        "        label_string = ''.join([PHONEME_MAP[index] for index in label_index])\n",
        "        dist += Levenshtein.distance(pred_string, label_string)\n",
        "\n",
        "    dist /= batch_size # TODO: Uncomment this, but think about why we are doing this\n",
        "    # raise NotImplemented\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qk9iZud1LXT"
      },
      "source": [
        "# Test Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnTLL-5gMBrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "933407f4-4968-4323-e070-497443bd37cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63.640625\n"
          ]
        }
      ],
      "source": [
        "# test code to check shapes\n",
        "\n",
        "model.eval()\n",
        "for i, data in enumerate(val_loader, 0):\n",
        "    x, y, lx, ly = data\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    h, lh = model(x, lx)\n",
        "    # print(h.shape)\n",
        "    h = torch.permute(h, (1, 0, 2))\n",
        "    # print(h.shape, y.shape)\n",
        "    loss = criterion(h, y, lh, ly)\n",
        "    # print(loss)\n",
        "    # print(h.shape, lh.shape, y.shape, ly.shape)\n",
        "    h = torch.permute(h, (1, 0, 2))\n",
        "    print(calculate_levenshtein(h, y, lh, ly, decoder, LABELS))\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd5aNaLVoR_g"
      },
      "source": [
        "# WandB\n",
        "\n",
        "You will need to fetch your api key from wandb.ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiDduMaDIARE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc92dda-856e-407b-d23f-3ae2fc8ba2ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabk171\u001b[0m (\u001b[33mabk171-university-of-pittsburgh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login(key=\"6e6412a1eff673cacdcda973f6e61422daaa9387\") # API Key is in your wandb account, under settings (wandb.ai/settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4s52yBOvICPZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "6a07f6a9-d0e5-4978-dd9f-b1c8cb067dfe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:f6ec7g57) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_dist</td><td>█▅▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>0.002</td></tr><tr><td>train_loss</td><td>0.12979</td></tr><tr><td>valid_dist</td><td>6.13658</td></tr><tr><td>valid_loss</td><td>0.34818</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">complete_better_embedding</strong> at: <a href='https://wandb.ai/abk171-university-of-pittsburgh/hw3p2-ablations/runs/f6ec7g57' target=\"_blank\">https://wandb.ai/abk171-university-of-pittsburgh/hw3p2-ablations/runs/f6ec7g57</a><br/> View project at: <a href='https://wandb.ai/abk171-university-of-pittsburgh/hw3p2-ablations' target=\"_blank\">https://wandb.ai/abk171-university-of-pittsburgh/hw3p2-ablations</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241111_171351-f6ec7g57/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:f6ec7g57). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241111_180556-jad4my4y</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abk171-university-of-pittsburgh/hw3p2-ablations/runs/jad4my4y' target=\"_blank\">complete_better_embedding_lower_thresh</a></strong> to <a href='https://wandb.ai/abk171-university-of-pittsburgh/hw3p2-ablations' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abk171-university-of-pittsburgh/hw3p2-ablations' target=\"_blank\">https://wandb.ai/abk171-university-of-pittsburgh/hw3p2-ablations</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abk171-university-of-pittsburgh/hw3p2-ablations/runs/jad4my4y' target=\"_blank\">https://wandb.ai/abk171-university-of-pittsburgh/hw3p2-ablations/runs/jad4my4y</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    name = \"complete_better_embedding_lower_thresh\", ## Wandb creates random run names if you skip this field\n",
        "    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    # run_id = ### Insert specific run id here if you want to resume a previous run\n",
        "    # resume = True, ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"hw3p2-ablations\", ### Project should be created in your wandb account\n",
        "    config = config ### Wandb Config for your run\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "5PlFls8ra97J",
        "outputId": "eabb5835-66e4-4f66-e917-ca23389fe788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-7da56333b3d5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDummy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_attaching\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0mquiet\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSet\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0mto\u001b[0m \u001b[0mminimize\u001b[0m \u001b[0mlog\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \"\"\"\n\u001b[0;32m-> 2139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexit_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     def _finish(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_finish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   2171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2173\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_atexit_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexit_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexit_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m             \u001b[0;31m# Run hooks that should happen after the last messages to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_atexit_cleanup\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2426\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2428\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_on_finish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2684\u001b[0m         \u001b[0;31m# Print some final statistics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2685\u001b[0m         \u001b[0mpoll_exit_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeliver_poll_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2686\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoll_exit_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2687\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2688\u001b[0m         progress.print_sync_dedupe_stats(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[1;32m    277\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mMailboxError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transport failed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mfound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabandoned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_and_clear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0;31m# Always update progress to 100% when done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\u001b[0m in \u001b[0;36m_get_and_clear\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_and_clear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_and_clear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fLLj5KIMMOe"
      },
      "source": [
        "# Train Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ri87MAdhMUz5"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer):\n",
        "\n",
        "    model.train()\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x, y, lx, ly = data\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            h, lh = model(x, lx)\n",
        "            h = torch.permute(h, (1, 0, 2))\n",
        "            loss = criterion(h, y, lh, ly)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            lr=\"{:.06f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "\n",
        "        batch_bar.update() # Update tqdm bar\n",
        "\n",
        "        # Another couple things you need for FP16.\n",
        "        scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
        "        scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
        "        scaler.update() # This is something added just for FP16\n",
        "\n",
        "        del x, y, lx, ly, h, lh, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "\n",
        "def validate_model(model, val_loader, decoder, phoneme_map= LABELS):\n",
        "\n",
        "    model.eval()\n",
        "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "\n",
        "    total_loss = 0\n",
        "    vdist = 0\n",
        "\n",
        "    for i, data in enumerate(val_loader):\n",
        "\n",
        "        x, y, lx, ly = data\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            h, lh = model(x, lx)\n",
        "            h = torch.permute(h, (1, 0, 2))\n",
        "            loss = criterion(h, y, lh, ly)\n",
        "\n",
        "        total_loss += float(loss)\n",
        "        vdist += calculate_levenshtein(torch.permute(h, (1, 0, 2)), y, lh, ly, decoder, phoneme_map)\n",
        "\n",
        "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))), dist=\"{:.04f}\".format(float(vdist / (i + 1))))\n",
        "\n",
        "        batch_bar.update()\n",
        "\n",
        "        del x, y, lx, ly, h, lh, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close()\n",
        "    total_loss = total_loss/len(val_loader)\n",
        "    val_dist = vdist/len(val_loader)\n",
        "    return total_loss, val_dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpYExu4vT4_g"
      },
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "husa5_EYMUz6"
      },
      "outputs": [],
      "source": [
        "def save_model(model, optimizer, scheduler, metric, epoch, path):\n",
        "    torch.save(\n",
        "        {'model_state_dict'         : model.state_dict(),\n",
        "         'optimizer_state_dict'     : optimizer.state_dict(),\n",
        "         'scheduler_state_dict'     : scheduler.state_dict(),\n",
        "         metric[0]                  : metric[1],\n",
        "         'epoch'                    : epoch},\n",
        "         path\n",
        "    )\n",
        "\n",
        "def load_model(path, model, metric= 'valid_acc', optimizer= None, scheduler= None):\n",
        "\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    if optimizer != None:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    if scheduler != None:\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "    epoch   = checkpoint['epoch']\n",
        "    # metric  = checkpoint[metric]\n",
        "\n",
        "    return [model, optimizer, scheduler, epoch, metric]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tExvyl1BIdMC"
      },
      "outputs": [],
      "source": [
        "# This is for checkpointing, if you're doing it over multiple sessions\n",
        "\n",
        "last_epoch_completed = 0\n",
        "start = last_epoch_completed\n",
        "end = config[\"epochs\"]\n",
        "best_lev_dist = float(\"inf\") # if you're restarting from some checkpoint, use what you saw there.\n",
        "epoch_model_path = '/epoch_model.pth'#TODO set the model path( Optional, you can just store best one. Make sure to make the changes below )\n",
        "best_model_path = '/best_model.pth'#TODO set best model path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JR43E28rM9Ak",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a9ce4288-7b3d-4f3c-aaa1-e9a38e839db9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 1.5775\t Learning Rate 0.0020000\n",
            "\tVal Dist 15.2051%\t Val Loss 0.6909\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.6019\t Learning Rate 0.0020000\n",
            "\tVal Dist 11.3153%\t Val Loss 0.5213\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.4593\t Learning Rate 0.0020000\n",
            "\tVal Dist 9.6789%\t Val Loss 0.4510\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.3813\t Learning Rate 0.0020000\n",
            "\tVal Dist 8.7610%\t Val Loss 0.4144\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.3273\t Learning Rate 0.0020000\n",
            "\tVal Dist 7.8114%\t Val Loss 0.3757\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2886\t Learning Rate 0.0020000\n",
            "\tVal Dist 7.5352%\t Val Loss 0.3667\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2619\t Learning Rate 0.0020000\n",
            "\tVal Dist 7.1154%\t Val Loss 0.3502\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2374\t Learning Rate 0.0020000\n",
            "\tVal Dist 7.0513%\t Val Loss 0.3505\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.2018\t Learning Rate 0.0016000\n",
            "\tVal Dist 6.4797%\t Val Loss 0.3349\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1845\t Learning Rate 0.0016000\n",
            "\tVal Dist 6.4199%\t Val Loss 0.3363\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1737\t Learning Rate 0.0016000\n",
            "\tVal Dist 6.3509%\t Val Loss 0.3343\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1632\t Learning Rate 0.0016000\n",
            "\tVal Dist 6.3037%\t Val Loss 0.3389\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1407\t Learning Rate 0.0012800\n",
            "\tVal Dist 6.0580%\t Val Loss 0.3375\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1316\t Learning Rate 0.0012800\n",
            "\tVal Dist 6.0534%\t Val Loss 0.3410\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1244\t Learning Rate 0.0012800\n",
            "\tVal Dist 6.0810%\t Val Loss 0.3456\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 16/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1085\t Learning Rate 0.0010240\n",
            "\tVal Dist 5.8967%\t Val Loss 0.3474\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 17/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.1005\t Learning Rate 0.0010240\n",
            "\tVal Dist 5.8568%\t Val Loss 0.3518\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 18/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0969\t Learning Rate 0.0010240\n",
            "\tVal Dist 5.8596%\t Val Loss 0.3596\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 19/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0849\t Learning Rate 0.0008192\n",
            "\tVal Dist 5.7087%\t Val Loss 0.3629\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 20/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0807\t Learning Rate 0.0008192\n",
            "\tVal Dist 5.8486%\t Val Loss 0.3760\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 21/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss 0.0768\t Learning Rate 0.0008192\n",
            "\tVal Dist 5.7501%\t Val Loss 0.3731\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 22/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  39%|███▉      | 175/446 [00:54<01:24,  3.20it/s, loss=0.0707, lr=0.000819]"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-20bfae423c9c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcurr_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m              \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dist\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphoneme_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLABELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-abb89d234fb2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Another couple things you need for FP16.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is a replacement for loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is a replacement for optimizer.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is something added just for FP16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             adamw(params_with_grad,\n\u001b[0m\u001b[1;32m    163\u001b[0m                   \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                   \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    220\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcapturable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "#TODO: Please complete the training loop\n",
        "\n",
        "for epoch in range(0, config['epochs']):\n",
        "\n",
        "    print(\"\\nEpoch: {}/{}\".format(epoch+1, config['epochs']))\n",
        "\n",
        "    curr_lr = float(optimizer.param_groups[0]['lr'])#TODO\n",
        "\n",
        "    train_loss              = train_model(model=model,train_loader=train_loader,criterion=criterion,optimizer=optimizer)#TODO\n",
        "    valid_loss, valid_dist  = validate_model(model=model,val_loader=val_loader,decoder=decoder,phoneme_map=LABELS)#TODO\n",
        "    scheduler.step(valid_dist)\n",
        "\n",
        "    print(\"\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_loss, curr_lr))\n",
        "    print(\"\\tVal Dist {:.04f}%\\t Val Loss {:.04f}\".format(valid_dist, valid_loss))\n",
        "\n",
        "\n",
        "    wandb.log({\n",
        "        'train_loss': train_loss,\n",
        "        'valid_dist': valid_dist,\n",
        "        'valid_loss': valid_loss,\n",
        "        'lr'        : curr_lr\n",
        "    })\n",
        "\n",
        "    save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, epoch_model_path)\n",
        "    # wandb.save(epoch_model_path)\n",
        "    print(\"Saved epoch model\")\n",
        "\n",
        "    if valid_dist <= best_lev_dist:\n",
        "        best_lev_dist = valid_dist\n",
        "        save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, best_model_path)\n",
        "        # wandb.save(best_model_path)\n",
        "        print(\"Saved best model\")\n",
        "      # You may find it interesting to exlplore Wandb Artifcats to version your models\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2H4EEj-sD32"
      },
      "source": [
        "# Generate Predictions and Submit to Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, _, _, _, _= load_model('/best_model.pth', model)"
      ],
      "metadata": {
        "id": "tJNIufQi0MaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2moYJhTWsOG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4f8b01-a407-427e-de0e-1911cb080c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/41 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/41 [00:01<00:40,  1.02s/it]\u001b[A\n",
            "  5%|▍         | 2/41 [00:02<00:42,  1.08s/it]\u001b[A\n",
            "  7%|▋         | 3/41 [00:03<00:40,  1.08s/it]\u001b[A\n",
            " 10%|▉         | 4/41 [00:04<00:37,  1.00s/it]\u001b[A\n",
            " 12%|█▏        | 5/41 [00:05<00:35,  1.01it/s]\u001b[A\n",
            " 15%|█▍        | 6/41 [00:05<00:30,  1.14it/s]\u001b[A\n",
            " 17%|█▋        | 7/41 [00:06<00:25,  1.33it/s]\u001b[A\n",
            " 20%|█▉        | 8/41 [00:07<00:25,  1.27it/s]\u001b[A\n",
            " 22%|██▏       | 9/41 [00:08<00:26,  1.20it/s]\u001b[A\n",
            " 24%|██▍       | 10/41 [00:09<00:28,  1.11it/s]\u001b[A\n",
            " 27%|██▋       | 11/41 [00:09<00:23,  1.26it/s]\u001b[A\n",
            " 29%|██▉       | 12/41 [00:10<00:22,  1.31it/s]\u001b[A\n",
            " 32%|███▏      | 13/41 [00:10<00:19,  1.42it/s]\u001b[A\n",
            " 34%|███▍      | 14/41 [00:11<00:20,  1.31it/s]\u001b[A\n",
            " 37%|███▋      | 15/41 [00:12<00:21,  1.19it/s]\u001b[A\n",
            " 39%|███▉      | 16/41 [00:13<00:22,  1.12it/s]\u001b[A\n",
            " 41%|████▏     | 17/41 [00:14<00:23,  1.02it/s]\u001b[A\n",
            " 44%|████▍     | 18/41 [00:15<00:22,  1.04it/s]\u001b[A\n",
            " 46%|████▋     | 19/41 [00:16<00:17,  1.24it/s]\u001b[A\n",
            " 49%|████▉     | 20/41 [00:17<00:17,  1.20it/s]\u001b[A\n",
            " 51%|█████     | 21/41 [00:18<00:17,  1.17it/s]\u001b[A\n",
            " 54%|█████▎    | 22/41 [00:19<00:16,  1.16it/s]\u001b[A\n",
            " 56%|█████▌    | 23/41 [00:19<00:15,  1.13it/s]\u001b[A\n",
            " 59%|█████▊    | 24/41 [00:20<00:12,  1.33it/s]\u001b[A\n",
            " 61%|██████    | 25/41 [00:21<00:13,  1.17it/s]\u001b[A\n",
            " 63%|██████▎   | 26/41 [00:22<00:12,  1.19it/s]\u001b[A\n",
            " 66%|██████▌   | 27/41 [00:22<00:10,  1.32it/s]\u001b[A\n",
            " 68%|██████▊   | 28/41 [00:23<00:09,  1.41it/s]\u001b[A\n",
            " 71%|███████   | 29/41 [00:24<00:08,  1.39it/s]\u001b[A\n",
            " 73%|███████▎  | 30/41 [00:24<00:07,  1.48it/s]\u001b[A\n",
            " 76%|███████▌  | 31/41 [00:25<00:07,  1.41it/s]\u001b[A\n",
            " 78%|███████▊  | 32/41 [00:26<00:06,  1.33it/s]\u001b[A\n",
            " 80%|████████  | 33/41 [00:27<00:06,  1.29it/s]\u001b[A\n",
            " 83%|████████▎ | 34/41 [00:28<00:05,  1.27it/s]\u001b[A\n",
            " 85%|████████▌ | 35/41 [00:28<00:04,  1.27it/s]\u001b[A\n",
            " 88%|████████▊ | 36/41 [00:30<00:04,  1.03it/s]\u001b[A\n",
            " 90%|█████████ | 37/41 [00:31<00:04,  1.04s/it]\u001b[A\n",
            " 93%|█████████▎| 38/41 [00:32<00:02,  1.06it/s]\u001b[A\n",
            " 95%|█████████▌| 39/41 [00:32<00:01,  1.14it/s]\u001b[A\n",
            " 98%|█████████▊| 40/41 [00:33<00:00,  1.13it/s]\u001b[A\n",
            "100%|██████████| 41/41 [00:34<00:00,  1.18it/s]\n"
          ]
        }
      ],
      "source": [
        "#TODO: Make predictions\n",
        "\n",
        "# Follow the steps below:\n",
        "# 1. Create a new object for CTCBeamDecoder with larger (why?) number of beams\n",
        "# 2. Get prediction string by decoding the results of the beam decoder\n",
        "\n",
        "TEST_BEAM_WIDTH = 20#TODO\n",
        "\n",
        "test_decoder    = CTCBeamDecoder(\n",
        "    labels= LABELS,\n",
        "    cutoff_top_n= 40,\n",
        "    beam_width= TEST_BEAM_WIDTH,\n",
        "    log_probs_input= True,\n",
        "    num_processes= 2\n",
        ")#TODO\n",
        "results = []\n",
        "\n",
        "model.eval()\n",
        "print(\"Testing\")\n",
        "for data in tqdm(test_loader):\n",
        "\n",
        "    x, lx   = data\n",
        "    x       = x.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        h, lh = model(x, lx)\n",
        "\n",
        "    prediction_string= decode_prediction(h, lh, test_decoder, LABELS)# TODO call decode_prediction\n",
        "    #TODO save the output in results array.\n",
        "    for prediction in prediction_string:\n",
        "        results.append(prediction)\n",
        "\n",
        "    del x, lx, h, lh\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d70dvu_lsMlv"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/11785-f24-hw3p2/test-clean/random_submission.csv\"\n",
        "df = pd.read_csv(data_dir)\n",
        "df.label = results\n",
        "df.to_csv('submission.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1sZmEIs4yIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e5333f-ed76-4236-a3bb-5be229905bbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.17 / client 1.5.8)\n",
            "100% 209k/209k [00:00<00:00, 329kB/s]\n",
            "Successfully submitted to Automatic Speech Recognition (ASR) Slack"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c automatic-speech-recognition-asr-slack -f submission.csv -m \"I made it!\"\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "UR4qfYrVoO4v",
        "gg3-yJ8tok34",
        "R9v5ewZDMpYA",
        "HLad4pChcuvX",
        "tUThsowyQdN7"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}